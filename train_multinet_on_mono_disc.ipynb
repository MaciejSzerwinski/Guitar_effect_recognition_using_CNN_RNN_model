{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-12T10:58:14.622387Z",
     "start_time": "2024-09-12T10:58:12.074976Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import dataset.dataset as dataset\n",
    "import datasplit.datasplit as datasplit\n",
    "import model.models as models\n",
    "import trainer.trainer as trainer\n",
    "import utils.utils as utils\n",
    "\n",
    "torch.cuda.device_count()\n",
    "\n",
    "cuda0 = torch.device('cuda:0')\n",
    "cuda1 = torch.device('cuda:1')\n",
    "cuda2 = torch.device('cuda:2')\n",
    "cuda3 = torch.device('cuda:3')\n",
    "\n",
    "device = torch.device(cuda0 if torch.cuda.is_available() else \"cpu\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T10:58:16.649595Z",
     "start_time": "2024-09-12T10:58:14.624494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# transforms\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "# dataset\n",
    "root = 'G:/PracaMagisterska/Dane/Mono_Discret_Audio'\n",
    "excl_folders = ['MT2']\n",
    "spectra_folder= 'mel_22050_1024_512'\n",
    "proc_settings_csv = 'proc_settings.csv'\n",
    "max_num_settings=3\n",
    "\n",
    "dataset = dataset.FxDataset(root=root,\n",
    "                            excl_folders=excl_folders, \n",
    "                            spectra_folder=spectra_folder, \n",
    "                            processed_settings_csv=proc_settings_csv,\n",
    "                            max_num_settings=max_num_settings,\n",
    "                            transform=transform)\n",
    "dataset.init_dataset()\n",
    "# dataset.generate_mel()\n",
    "\n",
    "# split\n",
    "split = datasplit.DataSplit(dataset, shuffle=True)\n",
    "\n",
    "# loaders\n",
    "train_loader, val_loader, test_loader = split.get_split(batch_size=100)\n",
    "\n",
    "print('dataset size: ', len(dataset))\n",
    "print('train set size: ', len(split.train_sampler))\n",
    "print('val set size: ', len(split.val_sampler))\n",
    "print('test set size: ', len(split.test_sampler))\n",
    "dataset.fx_to_label"
   ],
   "id": "7ce71d9078de6215",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size:  123552\n",
      "train set size:  88956\n",
      "val set size:  9885\n",
      "test set size:  24711\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'808': 0,\n",
       " 'BD2': 1,\n",
       " 'BMF': 2,\n",
       " 'DPL': 3,\n",
       " 'DS1': 4,\n",
       " 'FFC': 5,\n",
       " 'MGS': 6,\n",
       " 'OD1': 7,\n",
       " 'RAT': 8,\n",
       " 'RBM': 9,\n",
       " 'SD1': 10,\n",
       " 'TS9': 11,\n",
       " 'VTB': 12}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T10:58:16.665596Z",
     "start_time": "2024-09-12T10:58:16.650738Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# model\n",
    "input_size = 87  # Update this to match the feature size of your input\n",
    "hidden_size = 128  # You can adjust this as needed\n",
    "num_layers = 2  # You can adjust this as needed\n",
    "\n",
    "multinet = models.MultiRNN(n_classes=dataset.num_fx, n_settings=dataset.max_num_settings, input_size=input_size, hidden_size=hidden_size, num_layers=num_layers).to(device)\n",
    "# optimizer\n",
    "optimizer_multinet = optim.Adam(multinet.parameters(), lr=0.001)\n",
    "# loss function\n",
    "# loss function\n",
    "loss_func_fx = nn.CrossEntropyLoss()\n",
    "loss_func_set = nn.MSELoss(reduction='mean')\n",
    "\n",
    "print(multinet)\n",
    "print('Trainable Params: ', sum(p.numel() for p in multinet.parameters() if p.requires_grad))"
   ],
   "id": "e574c097255937f4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiRNN(\n",
      "  (lstm): LSTM(87, 128, num_layers=2, batch_first=True)\n",
      "  (fc1_a): Linear(in_features=128, out_features=120, bias=True)\n",
      "  (fc2_a): Linear(in_features=120, out_features=60, bias=True)\n",
      "  (out_a): Linear(in_features=60, out_features=13, bias=True)\n",
      "  (fc1_b): Linear(in_features=128, out_features=120, bias=True)\n",
      "  (fc2_b): Linear(in_features=120, out_features=60, bias=True)\n",
      "  (out_b): Linear(in_features=60, out_features=3, bias=True)\n",
      ")\n",
      "Trainable Params:  289656\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T10:58:16.680895Z",
     "start_time": "2024-09-12T10:58:16.666613Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# SAVE\n",
    "models_folder = 'G:/PracaMagisterska/Kod_na_magisterke/gfx-classifier_RNN_version-models_and_results/models'\n",
    "model_name = '20201110_multinet_mono_disc_best'\n",
    "results_folder = 'G:/PracaMagisterska/Kod_na_magisterke/gfx-classifier_RNN_version-models_and_results/result'\n",
    "results_subfolder = '20201110_multinet_mono_disc'"
   ],
   "id": "30b09b438a65ec4",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T01:46:56.353951Z",
     "start_time": "2024-09-12T10:58:16.681919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# TRAIN and TEST MultiNet OVER MULTIPLE EPOCHS\n",
    "train_set_size = len(split.train_sampler)\n",
    "val_set_size = len(split.val_sampler)\n",
    "test_set_size = len(split.test_sampler)\n",
    "\n",
    "all_train_losses, all_val_losses, all_test_losses = [],[],[]\n",
    "all_train_correct, all_val_correct, all_test_correct = [],[],[]\n",
    "all_train_results, all_val_results, all_test_results = [],[],[]\n",
    "\n",
    "best_val_correct = 0\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for epoch in range(50):\n",
    "    train_loss, train_correct, train_results = trainer.train_multi_net(\n",
    "        model=multinet,\n",
    "        optimizer=optimizer_multinet, \n",
    "        train_loader=train_loader, \n",
    "        train_sampler=split.train_sampler, \n",
    "        epoch=epoch, \n",
    "        loss_function_fx=loss_func_fx, \n",
    "        loss_function_set=loss_func_set,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    val_loss, val_correct, val_results = trainer.val_multi_net(\n",
    "        model=multinet,\n",
    "        val_loader=val_loader, \n",
    "        val_sampler=split.val_sampler, \n",
    "        loss_function_fx=loss_func_fx, \n",
    "        loss_function_set=loss_func_set,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    test_loss, test_correct, test_results = trainer.test_multi_net(\n",
    "        model=multinet,\n",
    "        test_loader=test_loader, \n",
    "        test_sampler=split.test_sampler, \n",
    "        loss_function_fx=loss_func_fx, \n",
    "        loss_function_set=loss_func_set,\n",
    "        device=device\n",
    "    )\n",
    "    # save model\n",
    "    if val_correct > best_val_correct:\n",
    "        best_val_correct = val_correct\n",
    "        torch.save(multinet, '%s/%s' % (models_folder, model_name))\n",
    "        print('\\n=== saved best model ===\\n')\n",
    "        \n",
    "    # append results\n",
    "    all_train_losses.append(train_loss)\n",
    "    all_val_losses.append(val_loss)\n",
    "    all_test_losses.append(test_loss)\n",
    "    \n",
    "    all_train_correct.append(train_correct)\n",
    "    all_val_correct.append(val_correct)\n",
    "    all_test_correct.append(test_correct)\n",
    "    \n",
    "    all_train_results.append(train_results)\n",
    "    all_val_results.append(val_results)\n",
    "    all_test_results.append(test_results)\n",
    "\n",
    "stop = time.time()\n",
    "print(f\"Training time: {stop - start}s\")"
   ],
   "id": "2ee6fafebcf8639d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0\t[5000/88956 (6%)]\tTotal Loss: 138.1869\tAvg Loss: 0.0276\n",
      "Train Epoch: 0\t[10000/88956 (11%)]\tTotal Loss: 266.4475\tAvg Loss: 0.0266\n",
      "Train Epoch: 0\t[15000/88956 (17%)]\tTotal Loss: 392.5159\tAvg Loss: 0.0262\n",
      "Train Epoch: 0\t[20000/88956 (22%)]\tTotal Loss: 509.9446\tAvg Loss: 0.0255\n",
      "Train Epoch: 0\t[25000/88956 (28%)]\tTotal Loss: 624.0031\tAvg Loss: 0.0250\n",
      "Train Epoch: 0\t[30000/88956 (34%)]\tTotal Loss: 735.3319\tAvg Loss: 0.0245\n",
      "Train Epoch: 0\t[35000/88956 (39%)]\tTotal Loss: 844.0400\tAvg Loss: 0.0241\n",
      "Train Epoch: 0\t[40000/88956 (45%)]\tTotal Loss: 951.9737\tAvg Loss: 0.0238\n",
      "Train Epoch: 0\t[45000/88956 (51%)]\tTotal Loss: 1059.1489\tAvg Loss: 0.0235\n",
      "Train Epoch: 0\t[50000/88956 (56%)]\tTotal Loss: 1164.3401\tAvg Loss: 0.0233\n",
      "Train Epoch: 0\t[55000/88956 (62%)]\tTotal Loss: 1265.7286\tAvg Loss: 0.0230\n",
      "Train Epoch: 0\t[60000/88956 (67%)]\tTotal Loss: 1362.9278\tAvg Loss: 0.0227\n",
      "Train Epoch: 0\t[65000/88956 (73%)]\tTotal Loss: 1457.1253\tAvg Loss: 0.0224\n",
      "Train Epoch: 0\t[70000/88956 (79%)]\tTotal Loss: 1547.0618\tAvg Loss: 0.0221\n",
      "Train Epoch: 0\t[75000/88956 (84%)]\tTotal Loss: 1633.3739\tAvg Loss: 0.0218\n",
      "Train Epoch: 0\t[80000/88956 (90%)]\tTotal Loss: 1715.2628\tAvg Loss: 0.0214\n",
      "Train Epoch: 0\t[85000/88956 (96%)]\tTotal Loss: 1790.6019\tAvg Loss: 0.0211\n",
      "====> Epoch: 0\tTotal Loss: 1848.1600\t Avg Loss: 0.0208\t Fx Loss: 1731.5159\t Set Loss: 116.6441\n",
      "\t\tCorrect: 551/88956\tFx Correct: 22929/88956\tSet Correct: 1457/88956\n",
      "\t\tPercentage Correct: 0.62\tPercentage Fx Correct: 25.78\tPercentage Set Correct: 1.64\n",
      "====> Val Loss: 146.8160\t Avg Loss: 0.0149\t Fx Loss: 136.5894\t Set Loss: 10.2266\n",
      "\t\tCorrect: 146/9885\tFx Correct: 4674/9885\tSet Correct: 228/9885\n",
      "\t\tPercentage Correct: 1.48\tPercentage Fx Correct: 47.28\tPercentage Set Correct: 2.31\n",
      "====> Test Loss: 368.9938\t Avg Loss: 0.0149\t Fx Loss: 343.3427\t Set Loss: 25.6511\n",
      "\t\tCorrect: 354/24711\tFx Correct: 11551/24711\tSet Correct: 569/24711\n",
      "\t\tPercentage Correct: 1.43\tPercentage Fx Correct: 46.74\tPercentage Set Correct: 2.30\n",
      "\n",
      "=== saved best model ===\n",
      "\n",
      "Train Epoch: 1\t[5000/88956 (6%)]\tTotal Loss: 67.5493\tAvg Loss: 0.0135\n",
      "Train Epoch: 1\t[10000/88956 (11%)]\tTotal Loss: 123.1826\tAvg Loss: 0.0123\n",
      "Train Epoch: 1\t[15000/88956 (17%)]\tTotal Loss: 175.3695\tAvg Loss: 0.0117\n",
      "Train Epoch: 1\t[20000/88956 (22%)]\tTotal Loss: 224.5891\tAvg Loss: 0.0112\n",
      "Train Epoch: 1\t[25000/88956 (28%)]\tTotal Loss: 271.9952\tAvg Loss: 0.0109\n",
      "Train Epoch: 1\t[30000/88956 (34%)]\tTotal Loss: 320.6566\tAvg Loss: 0.0107\n",
      "Train Epoch: 1\t[35000/88956 (39%)]\tTotal Loss: 362.2721\tAvg Loss: 0.0104\n",
      "Train Epoch: 1\t[40000/88956 (45%)]\tTotal Loss: 402.3831\tAvg Loss: 0.0101\n",
      "Train Epoch: 1\t[45000/88956 (51%)]\tTotal Loss: 442.0883\tAvg Loss: 0.0098\n",
      "Train Epoch: 1\t[50000/88956 (56%)]\tTotal Loss: 478.5547\tAvg Loss: 0.0096\n",
      "Train Epoch: 1\t[55000/88956 (62%)]\tTotal Loss: 513.7018\tAvg Loss: 0.0093\n",
      "Train Epoch: 1\t[60000/88956 (67%)]\tTotal Loss: 548.0117\tAvg Loss: 0.0091\n",
      "Train Epoch: 1\t[65000/88956 (73%)]\tTotal Loss: 581.8972\tAvg Loss: 0.0090\n",
      "Train Epoch: 1\t[70000/88956 (79%)]\tTotal Loss: 614.3457\tAvg Loss: 0.0088\n",
      "Train Epoch: 1\t[75000/88956 (84%)]\tTotal Loss: 645.6830\tAvg Loss: 0.0086\n",
      "Train Epoch: 1\t[80000/88956 (90%)]\tTotal Loss: 675.1604\tAvg Loss: 0.0084\n",
      "Train Epoch: 1\t[85000/88956 (96%)]\tTotal Loss: 706.8492\tAvg Loss: 0.0083\n",
      "====> Epoch: 1\tTotal Loss: 729.7816\t Avg Loss: 0.0082\t Fx Loss: 652.8249\t Set Loss: 76.9567\n",
      "\t\tCorrect: 2761/88956\tFx Correct: 61683/88956\tSet Correct: 3346/88956\n",
      "\t\tPercentage Correct: 3.10\tPercentage Fx Correct: 69.34\tPercentage Set Correct: 3.76\n",
      "====> Val Loss: 58.2032\t Avg Loss: 0.0059\t Fx Loss: 50.5042\t Set Loss: 7.6990\n",
      "\t\tCorrect: 465/9885\tFx Correct: 7589/9885\tSet Correct: 566/9885\n",
      "\t\tPercentage Correct: 4.70\tPercentage Fx Correct: 76.77\tPercentage Set Correct: 5.73\n",
      "====> Test Loss: 143.9552\t Avg Loss: 0.0058\t Fx Loss: 124.6986\t Set Loss: 19.2566\n",
      "\t\tCorrect: 1226/24711\tFx Correct: 19158/24711\tSet Correct: 1447/24711\n",
      "\t\tPercentage Correct: 4.96\tPercentage Fx Correct: 77.53\tPercentage Set Correct: 5.86\n",
      "\n",
      "=== saved best model ===\n",
      "\n",
      "Train Epoch: 2\t[5000/88956 (6%)]\tTotal Loss: 28.0131\tAvg Loss: 0.0056\n",
      "Train Epoch: 2\t[10000/88956 (11%)]\tTotal Loss: 55.3476\tAvg Loss: 0.0055\n",
      "Train Epoch: 2\t[15000/88956 (17%)]\tTotal Loss: 82.8197\tAvg Loss: 0.0055\n",
      "Train Epoch: 2\t[20000/88956 (22%)]\tTotal Loss: 110.2785\tAvg Loss: 0.0055\n",
      "Train Epoch: 2\t[25000/88956 (28%)]\tTotal Loss: 135.2887\tAvg Loss: 0.0054\n",
      "Train Epoch: 2\t[30000/88956 (34%)]\tTotal Loss: 160.7011\tAvg Loss: 0.0054\n",
      "Train Epoch: 2\t[35000/88956 (39%)]\tTotal Loss: 186.1888\tAvg Loss: 0.0053\n",
      "Train Epoch: 2\t[40000/88956 (45%)]\tTotal Loss: 210.2118\tAvg Loss: 0.0053\n",
      "Train Epoch: 2\t[45000/88956 (51%)]\tTotal Loss: 234.6951\tAvg Loss: 0.0052\n",
      "Train Epoch: 2\t[50000/88956 (56%)]\tTotal Loss: 259.1771\tAvg Loss: 0.0052\n",
      "Train Epoch: 2\t[55000/88956 (62%)]\tTotal Loss: 283.0462\tAvg Loss: 0.0051\n",
      "Train Epoch: 2\t[60000/88956 (67%)]\tTotal Loss: 306.8504\tAvg Loss: 0.0051\n",
      "Train Epoch: 2\t[65000/88956 (73%)]\tTotal Loss: 330.0475\tAvg Loss: 0.0051\n",
      "Train Epoch: 2\t[70000/88956 (79%)]\tTotal Loss: 352.1204\tAvg Loss: 0.0050\n",
      "Train Epoch: 2\t[75000/88956 (84%)]\tTotal Loss: 374.4819\tAvg Loss: 0.0050\n",
      "Train Epoch: 2\t[80000/88956 (90%)]\tTotal Loss: 397.8426\tAvg Loss: 0.0050\n",
      "Train Epoch: 2\t[85000/88956 (96%)]\tTotal Loss: 419.1913\tAvg Loss: 0.0049\n",
      "====> Epoch: 2\tTotal Loss: 437.0714\t Avg Loss: 0.0049\t Fx Loss: 380.9426\t Set Loss: 56.1288\n",
      "\t\tCorrect: 5970/88956\tFx Correct: 70987/88956\tSet Correct: 6756/88956\n",
      "\t\tPercentage Correct: 6.71\tPercentage Fx Correct: 79.80\tPercentage Set Correct: 7.59\n",
      "====> Val Loss: 41.9888\t Avg Loss: 0.0042\t Fx Loss: 36.1861\t Set Loss: 5.8027\n",
      "\t\tCorrect: 770/9885\tFx Correct: 8108/9885\tSet Correct: 875/9885\n",
      "\t\tPercentage Correct: 7.79\tPercentage Fx Correct: 82.02\tPercentage Set Correct: 8.85\n",
      "====> Test Loss: 103.9778\t Avg Loss: 0.0042\t Fx Loss: 89.4189\t Set Loss: 14.5589\n",
      "\t\tCorrect: 1934/24711\tFx Correct: 20269/24711\tSet Correct: 2160/24711\n",
      "\t\tPercentage Correct: 7.83\tPercentage Fx Correct: 82.02\tPercentage Set Correct: 8.74\n",
      "\n",
      "=== saved best model ===\n",
      "\n",
      "Train Epoch: 3\t[5000/88956 (6%)]\tTotal Loss: 23.7899\tAvg Loss: 0.0048\n",
      "Train Epoch: 3\t[10000/88956 (11%)]\tTotal Loss: 43.9961\tAvg Loss: 0.0044\n",
      "Train Epoch: 3\t[15000/88956 (17%)]\tTotal Loss: 63.9818\tAvg Loss: 0.0043\n",
      "Train Epoch: 3\t[20000/88956 (22%)]\tTotal Loss: 84.6576\tAvg Loss: 0.0042\n",
      "Train Epoch: 3\t[25000/88956 (28%)]\tTotal Loss: 104.3303\tAvg Loss: 0.0042\n",
      "Train Epoch: 3\t[30000/88956 (34%)]\tTotal Loss: 124.0481\tAvg Loss: 0.0041\n",
      "Train Epoch: 3\t[35000/88956 (39%)]\tTotal Loss: 144.2674\tAvg Loss: 0.0041\n",
      "Train Epoch: 3\t[40000/88956 (45%)]\tTotal Loss: 164.8619\tAvg Loss: 0.0041\n",
      "Train Epoch: 3\t[45000/88956 (51%)]\tTotal Loss: 183.7517\tAvg Loss: 0.0041\n",
      "Train Epoch: 3\t[50000/88956 (56%)]\tTotal Loss: 203.3999\tAvg Loss: 0.0041\n",
      "Train Epoch: 3\t[55000/88956 (62%)]\tTotal Loss: 222.8209\tAvg Loss: 0.0041\n",
      "Train Epoch: 3\t[60000/88956 (67%)]\tTotal Loss: 242.9263\tAvg Loss: 0.0040\n",
      "Train Epoch: 3\t[65000/88956 (73%)]\tTotal Loss: 262.0000\tAvg Loss: 0.0040\n",
      "Train Epoch: 3\t[70000/88956 (79%)]\tTotal Loss: 281.0795\tAvg Loss: 0.0040\n",
      "Train Epoch: 3\t[75000/88956 (84%)]\tTotal Loss: 299.6961\tAvg Loss: 0.0040\n",
      "Train Epoch: 3\t[80000/88956 (90%)]\tTotal Loss: 318.0189\tAvg Loss: 0.0040\n",
      "Train Epoch: 3\t[85000/88956 (96%)]\tTotal Loss: 336.3861\tAvg Loss: 0.0040\n",
      "====> Epoch: 3\tTotal Loss: 350.5055\t Avg Loss: 0.0039\t Fx Loss: 303.3503\t Set Loss: 47.1551\n",
      "\t\tCorrect: 8625/88956\tFx Correct: 73680/88956\tSet Correct: 9557/88956\n",
      "\t\tPercentage Correct: 9.70\tPercentage Fx Correct: 82.83\tPercentage Set Correct: 10.74\n",
      "====> Val Loss: 34.3201\t Avg Loss: 0.0035\t Fx Loss: 29.7171\t Set Loss: 4.6031\n",
      "\t\tCorrect: 1133/9885\tFx Correct: 8348/9885\tSet Correct: 1248/9885\n",
      "\t\tPercentage Correct: 11.46\tPercentage Fx Correct: 84.45\tPercentage Set Correct: 12.63\n",
      "====> Test Loss: 86.2623\t Avg Loss: 0.0035\t Fx Loss: 74.5616\t Set Loss: 11.7007\n",
      "\t\tCorrect: 2786/24711\tFx Correct: 20755/24711\tSet Correct: 3063/24711\n",
      "\t\tPercentage Correct: 11.27\tPercentage Fx Correct: 83.99\tPercentage Set Correct: 12.40\n",
      "\n",
      "=== saved best model ===\n",
      "\n",
      "Train Epoch: 4\t[5000/88956 (6%)]\tTotal Loss: 17.7084\tAvg Loss: 0.0035\n",
      "Train Epoch: 4\t[10000/88956 (11%)]\tTotal Loss: 35.1130\tAvg Loss: 0.0035\n",
      "Train Epoch: 4\t[15000/88956 (17%)]\tTotal Loss: 52.3662\tAvg Loss: 0.0035\n",
      "Train Epoch: 4\t[20000/88956 (22%)]\tTotal Loss: 69.3912\tAvg Loss: 0.0035\n",
      "Train Epoch: 4\t[25000/88956 (28%)]\tTotal Loss: 86.7260\tAvg Loss: 0.0035\n",
      "Train Epoch: 4\t[30000/88956 (34%)]\tTotal Loss: 104.0858\tAvg Loss: 0.0035\n",
      "Train Epoch: 4\t[35000/88956 (39%)]\tTotal Loss: 121.5680\tAvg Loss: 0.0035\n",
      "Train Epoch: 4\t[40000/88956 (45%)]\tTotal Loss: 139.0973\tAvg Loss: 0.0035\n",
      "Train Epoch: 4\t[45000/88956 (51%)]\tTotal Loss: 156.5805\tAvg Loss: 0.0035\n",
      "Train Epoch: 4\t[50000/88956 (56%)]\tTotal Loss: 173.4882\tAvg Loss: 0.0035\n",
      "Train Epoch: 4\t[55000/88956 (62%)]\tTotal Loss: 190.7191\tAvg Loss: 0.0035\n",
      "Train Epoch: 4\t[60000/88956 (67%)]\tTotal Loss: 207.7812\tAvg Loss: 0.0035\n",
      "Train Epoch: 4\t[65000/88956 (73%)]\tTotal Loss: 224.1455\tAvg Loss: 0.0034\n",
      "Train Epoch: 4\t[70000/88956 (79%)]\tTotal Loss: 241.2154\tAvg Loss: 0.0034\n",
      "Train Epoch: 4\t[75000/88956 (84%)]\tTotal Loss: 258.0155\tAvg Loss: 0.0034\n",
      "Train Epoch: 4\t[80000/88956 (90%)]\tTotal Loss: 276.1758\tAvg Loss: 0.0035\n",
      "Train Epoch: 4\t[85000/88956 (96%)]\tTotal Loss: 292.6523\tAvg Loss: 0.0034\n",
      "====> Epoch: 4\tTotal Loss: 304.5033\t Avg Loss: 0.0034\t Fx Loss: 263.2222\t Set Loss: 41.2811\n",
      "\t\tCorrect: 11514/88956\tFx Correct: 75014/88956\tSet Correct: 12536/88956\n",
      "\t\tPercentage Correct: 12.94\tPercentage Fx Correct: 84.33\tPercentage Set Correct: 14.09\n",
      "====> Val Loss: 32.5589\t Avg Loss: 0.0033\t Fx Loss: 28.0038\t Set Loss: 4.5551\n",
      "\t\tCorrect: 1342/9885\tFx Correct: 8371/9885\tSet Correct: 1428/9885\n",
      "\t\tPercentage Correct: 13.58\tPercentage Fx Correct: 84.68\tPercentage Set Correct: 14.45\n",
      "====> Test Loss: 81.4221\t Avg Loss: 0.0033\t Fx Loss: 70.0914\t Set Loss: 11.3307\n",
      "\t\tCorrect: 3399/24711\tFx Correct: 20997/24711\tSet Correct: 3632/24711\n",
      "\t\tPercentage Correct: 13.76\tPercentage Fx Correct: 84.97\tPercentage Set Correct: 14.70\n",
      "\n",
      "=== saved best model ===\n",
      "\n",
      "Train Epoch: 5\t[5000/88956 (6%)]\tTotal Loss: 16.9729\tAvg Loss: 0.0034\n",
      "Train Epoch: 5\t[10000/88956 (11%)]\tTotal Loss: 32.6249\tAvg Loss: 0.0033\n",
      "Train Epoch: 5\t[15000/88956 (17%)]\tTotal Loss: 48.6290\tAvg Loss: 0.0032\n",
      "Train Epoch: 5\t[20000/88956 (22%)]\tTotal Loss: 66.0485\tAvg Loss: 0.0033\n",
      "Train Epoch: 5\t[25000/88956 (28%)]\tTotal Loss: 81.7587\tAvg Loss: 0.0033\n",
      "Train Epoch: 5\t[30000/88956 (34%)]\tTotal Loss: 98.2159\tAvg Loss: 0.0033\n",
      "Train Epoch: 5\t[35000/88956 (39%)]\tTotal Loss: 113.6188\tAvg Loss: 0.0032\n",
      "Train Epoch: 5\t[40000/88956 (45%)]\tTotal Loss: 129.4994\tAvg Loss: 0.0032\n",
      "Train Epoch: 5\t[45000/88956 (51%)]\tTotal Loss: 144.8483\tAvg Loss: 0.0032\n",
      "Train Epoch: 5\t[50000/88956 (56%)]\tTotal Loss: 160.5515\tAvg Loss: 0.0032\n",
      "Train Epoch: 5\t[55000/88956 (62%)]\tTotal Loss: 177.3071\tAvg Loss: 0.0032\n",
      "Train Epoch: 5\t[60000/88956 (67%)]\tTotal Loss: 192.0904\tAvg Loss: 0.0032\n",
      "Train Epoch: 5\t[65000/88956 (73%)]\tTotal Loss: 207.1101\tAvg Loss: 0.0032\n",
      "Train Epoch: 5\t[70000/88956 (79%)]\tTotal Loss: 222.3528\tAvg Loss: 0.0032\n",
      "Train Epoch: 5\t[75000/88956 (84%)]\tTotal Loss: 237.9441\tAvg Loss: 0.0032\n",
      "Train Epoch: 5\t[80000/88956 (90%)]\tTotal Loss: 254.3231\tAvg Loss: 0.0032\n",
      "Train Epoch: 5\t[85000/88956 (96%)]\tTotal Loss: 271.1853\tAvg Loss: 0.0032\n",
      "====> Epoch: 5\tTotal Loss: 283.3441\t Avg Loss: 0.0032\t Fx Loss: 245.6980\t Set Loss: 37.6461\n",
      "\t\tCorrect: 13183/88956\tFx Correct: 75675/88956\tSet Correct: 14378/88956\n",
      "\t\tPercentage Correct: 14.82\tPercentage Fx Correct: 85.07\tPercentage Set Correct: 16.16\n",
      "====> Val Loss: 30.2846\t Avg Loss: 0.0031\t Fx Loss: 26.1617\t Set Loss: 4.1229\n",
      "\t\tCorrect: 1505/9885\tFx Correct: 8455/9885\tSet Correct: 1614/9885\n",
      "\t\tPercentage Correct: 15.23\tPercentage Fx Correct: 85.53\tPercentage Set Correct: 16.33\n",
      "====> Test Loss: 75.5483\t Avg Loss: 0.0031\t Fx Loss: 65.1518\t Set Loss: 10.3965\n",
      "\t\tCorrect: 3686/24711\tFx Correct: 21017/24711\tSet Correct: 4003/24711\n",
      "\t\tPercentage Correct: 14.92\tPercentage Fx Correct: 85.05\tPercentage Set Correct: 16.20\n",
      "\n",
      "=== saved best model ===\n",
      "\n",
      "Train Epoch: 6\t[5000/88956 (6%)]\tTotal Loss: 15.5125\tAvg Loss: 0.0031\n",
      "Train Epoch: 6\t[10000/88956 (11%)]\tTotal Loss: 30.4166\tAvg Loss: 0.0030\n",
      "Train Epoch: 6\t[15000/88956 (17%)]\tTotal Loss: 45.0307\tAvg Loss: 0.0030\n",
      "Train Epoch: 6\t[20000/88956 (22%)]\tTotal Loss: 59.6052\tAvg Loss: 0.0030\n",
      "Train Epoch: 6\t[25000/88956 (28%)]\tTotal Loss: 75.4916\tAvg Loss: 0.0030\n",
      "Train Epoch: 6\t[30000/88956 (34%)]\tTotal Loss: 90.4791\tAvg Loss: 0.0030\n",
      "Train Epoch: 6\t[35000/88956 (39%)]\tTotal Loss: 105.6800\tAvg Loss: 0.0030\n",
      "Train Epoch: 6\t[40000/88956 (45%)]\tTotal Loss: 120.7093\tAvg Loss: 0.0030\n",
      "Train Epoch: 6\t[45000/88956 (51%)]\tTotal Loss: 136.0471\tAvg Loss: 0.0030\n",
      "Train Epoch: 6\t[50000/88956 (56%)]\tTotal Loss: 152.2948\tAvg Loss: 0.0030\n",
      "Train Epoch: 6\t[55000/88956 (62%)]\tTotal Loss: 167.6913\tAvg Loss: 0.0030\n",
      "Train Epoch: 6\t[60000/88956 (67%)]\tTotal Loss: 182.8682\tAvg Loss: 0.0030\n",
      "Train Epoch: 6\t[65000/88956 (73%)]\tTotal Loss: 198.1109\tAvg Loss: 0.0030\n",
      "Train Epoch: 6\t[70000/88956 (79%)]\tTotal Loss: 214.8434\tAvg Loss: 0.0031\n",
      "Train Epoch: 6\t[75000/88956 (84%)]\tTotal Loss: 230.2966\tAvg Loss: 0.0031\n",
      "Train Epoch: 6\t[80000/88956 (90%)]\tTotal Loss: 244.1336\tAvg Loss: 0.0031\n",
      "Train Epoch: 6\t[85000/88956 (96%)]\tTotal Loss: 258.3523\tAvg Loss: 0.0030\n",
      "====> Epoch: 6\tTotal Loss: 269.6076\t Avg Loss: 0.0030\t Fx Loss: 234.3553\t Set Loss: 35.2522\n",
      "\t\tCorrect: 14917/88956\tFx Correct: 75832/88956\tSet Correct: 16239/88956\n",
      "\t\tPercentage Correct: 16.77\tPercentage Fx Correct: 85.25\tPercentage Set Correct: 18.26\n",
      "====> Val Loss: 29.4846\t Avg Loss: 0.0030\t Fx Loss: 25.6259\t Set Loss: 3.8587\n",
      "\t\tCorrect: 1760/9885\tFx Correct: 8426/9885\tSet Correct: 1925/9885\n",
      "\t\tPercentage Correct: 17.80\tPercentage Fx Correct: 85.24\tPercentage Set Correct: 19.47\n",
      "====> Test Loss: 74.2101\t Avg Loss: 0.0030\t Fx Loss: 64.5381\t Set Loss: 9.6720\n",
      "\t\tCorrect: 4325/24711\tFx Correct: 21171/24711\tSet Correct: 4685/24711\n",
      "\t\tPercentage Correct: 17.50\tPercentage Fx Correct: 85.67\tPercentage Set Correct: 18.96\n",
      "\n",
      "=== saved best model ===\n",
      "\n",
      "Train Epoch: 7\t[5000/88956 (6%)]\tTotal Loss: 14.7962\tAvg Loss: 0.0030\n",
      "Train Epoch: 7\t[10000/88956 (11%)]\tTotal Loss: 29.2023\tAvg Loss: 0.0029\n",
      "Train Epoch: 7\t[15000/88956 (17%)]\tTotal Loss: 41.7618\tAvg Loss: 0.0028\n",
      "Train Epoch: 7\t[20000/88956 (22%)]\tTotal Loss: 55.9701\tAvg Loss: 0.0028\n",
      "Train Epoch: 7\t[25000/88956 (28%)]\tTotal Loss: 71.5527\tAvg Loss: 0.0029\n",
      "Train Epoch: 7\t[30000/88956 (34%)]\tTotal Loss: 86.4141\tAvg Loss: 0.0029\n",
      "Train Epoch: 7\t[35000/88956 (39%)]\tTotal Loss: 100.6484\tAvg Loss: 0.0029\n",
      "Train Epoch: 7\t[40000/88956 (45%)]\tTotal Loss: 114.1220\tAvg Loss: 0.0029\n",
      "Train Epoch: 7\t[45000/88956 (51%)]\tTotal Loss: 128.7379\tAvg Loss: 0.0029\n",
      "Train Epoch: 7\t[50000/88956 (56%)]\tTotal Loss: 142.2344\tAvg Loss: 0.0028\n",
      "Train Epoch: 7\t[55000/88956 (62%)]\tTotal Loss: 157.0755\tAvg Loss: 0.0029\n",
      "Train Epoch: 7\t[60000/88956 (67%)]\tTotal Loss: 172.1747\tAvg Loss: 0.0029\n",
      "Train Epoch: 7\t[65000/88956 (73%)]\tTotal Loss: 188.4963\tAvg Loss: 0.0029\n",
      "Train Epoch: 7\t[70000/88956 (79%)]\tTotal Loss: 202.7339\tAvg Loss: 0.0029\n",
      "Train Epoch: 7\t[75000/88956 (84%)]\tTotal Loss: 217.7805\tAvg Loss: 0.0029\n",
      "Train Epoch: 7\t[80000/88956 (90%)]\tTotal Loss: 231.8673\tAvg Loss: 0.0029\n",
      "Train Epoch: 7\t[85000/88956 (96%)]\tTotal Loss: 245.2406\tAvg Loss: 0.0029\n",
      "====> Epoch: 7\tTotal Loss: 255.7437\t Avg Loss: 0.0029\t Fx Loss: 222.9298\t Set Loss: 32.8140\n",
      "\t\tCorrect: 16552/88956\tFx Correct: 76247/88956\tSet Correct: 18120/88956\n",
      "\t\tPercentage Correct: 18.61\tPercentage Fx Correct: 85.71\tPercentage Set Correct: 20.37\n",
      "====> Val Loss: 26.3670\t Avg Loss: 0.0027\t Fx Loss: 22.9041\t Set Loss: 3.4628\n",
      "\t\tCorrect: 1990/9885\tFx Correct: 8513/9885\tSet Correct: 2147/9885\n",
      "\t\tPercentage Correct: 20.13\tPercentage Fx Correct: 86.12\tPercentage Set Correct: 21.72\n",
      "====> Test Loss: 67.0863\t Avg Loss: 0.0027\t Fx Loss: 58.3949\t Set Loss: 8.6914\n",
      "\t\tCorrect: 5075/24711\tFx Correct: 21378/24711\tSet Correct: 5450/24711\n",
      "\t\tPercentage Correct: 20.54\tPercentage Fx Correct: 86.51\tPercentage Set Correct: 22.05\n",
      "\n",
      "=== saved best model ===\n",
      "\n",
      "Train Epoch: 8\t[5000/88956 (6%)]\tTotal Loss: 13.0980\tAvg Loss: 0.0026\n",
      "Train Epoch: 8\t[10000/88956 (11%)]\tTotal Loss: 26.6984\tAvg Loss: 0.0027\n",
      "Train Epoch: 8\t[15000/88956 (17%)]\tTotal Loss: 40.0814\tAvg Loss: 0.0027\n",
      "Train Epoch: 8\t[20000/88956 (22%)]\tTotal Loss: 54.6759\tAvg Loss: 0.0027\n",
      "Train Epoch: 8\t[25000/88956 (28%)]\tTotal Loss: 68.2036\tAvg Loss: 0.0027\n",
      "Train Epoch: 8\t[30000/88956 (34%)]\tTotal Loss: 82.1027\tAvg Loss: 0.0027\n",
      "Train Epoch: 8\t[35000/88956 (39%)]\tTotal Loss: 96.9353\tAvg Loss: 0.0028\n",
      "Train Epoch: 8\t[40000/88956 (45%)]\tTotal Loss: 111.1984\tAvg Loss: 0.0028\n",
      "Train Epoch: 8\t[45000/88956 (51%)]\tTotal Loss: 125.0411\tAvg Loss: 0.0028\n",
      "Train Epoch: 8\t[50000/88956 (56%)]\tTotal Loss: 139.2453\tAvg Loss: 0.0028\n",
      "Train Epoch: 8\t[55000/88956 (62%)]\tTotal Loss: 153.4656\tAvg Loss: 0.0028\n",
      "Train Epoch: 8\t[60000/88956 (67%)]\tTotal Loss: 167.9806\tAvg Loss: 0.0028\n",
      "Train Epoch: 8\t[65000/88956 (73%)]\tTotal Loss: 181.8669\tAvg Loss: 0.0028\n",
      "Train Epoch: 8\t[70000/88956 (79%)]\tTotal Loss: 194.9980\tAvg Loss: 0.0028\n",
      "Train Epoch: 8\t[75000/88956 (84%)]\tTotal Loss: 209.8008\tAvg Loss: 0.0028\n",
      "Train Epoch: 8\t[80000/88956 (90%)]\tTotal Loss: 223.6771\tAvg Loss: 0.0028\n",
      "Train Epoch: 8\t[85000/88956 (96%)]\tTotal Loss: 237.5917\tAvg Loss: 0.0028\n",
      "====> Epoch: 8\tTotal Loss: 248.0995\t Avg Loss: 0.0028\t Fx Loss: 217.2535\t Set Loss: 30.8460\n",
      "\t\tCorrect: 17864/88956\tFx Correct: 76443/88956\tSet Correct: 19387/88956\n",
      "\t\tPercentage Correct: 20.08\tPercentage Fx Correct: 85.93\tPercentage Set Correct: 21.79\n",
      "====> Val Loss: 31.0151\t Avg Loss: 0.0031\t Fx Loss: 26.9646\t Set Loss: 4.0505\n",
      "\t\tCorrect: 1911/9885\tFx Correct: 8397/9885\tSet Correct: 2090/9885\n",
      "\t\tPercentage Correct: 19.33\tPercentage Fx Correct: 84.95\tPercentage Set Correct: 21.14\n",
      "====> Test Loss: 76.1845\t Avg Loss: 0.0031\t Fx Loss: 65.9507\t Set Loss: 10.2339\n",
      "\t\tCorrect: 4745/24711\tFx Correct: 21208/24711\tSet Correct: 5140/24711\n",
      "\t\tPercentage Correct: 19.20\tPercentage Fx Correct: 85.82\tPercentage Set Correct: 20.80\n",
      "Train Epoch: 9\t[5000/88956 (6%)]\tTotal Loss: 14.6108\tAvg Loss: 0.0029\n",
      "Train Epoch: 9\t[10000/88956 (11%)]\tTotal Loss: 28.2979\tAvg Loss: 0.0028\n",
      "Train Epoch: 9\t[15000/88956 (17%)]\tTotal Loss: 41.8461\tAvg Loss: 0.0028\n",
      "Train Epoch: 9\t[20000/88956 (22%)]\tTotal Loss: 54.6715\tAvg Loss: 0.0027\n",
      "Train Epoch: 9\t[25000/88956 (28%)]\tTotal Loss: 67.2760\tAvg Loss: 0.0027\n",
      "Train Epoch: 9\t[30000/88956 (34%)]\tTotal Loss: 80.6306\tAvg Loss: 0.0027\n",
      "Train Epoch: 9\t[35000/88956 (39%)]\tTotal Loss: 94.2473\tAvg Loss: 0.0027\n",
      "Train Epoch: 9\t[40000/88956 (45%)]\tTotal Loss: 109.5963\tAvg Loss: 0.0027\n",
      "Train Epoch: 9\t[45000/88956 (51%)]\tTotal Loss: 123.3304\tAvg Loss: 0.0027\n",
      "Train Epoch: 9\t[50000/88956 (56%)]\tTotal Loss: 137.0882\tAvg Loss: 0.0027\n",
      "Train Epoch: 9\t[55000/88956 (62%)]\tTotal Loss: 150.1785\tAvg Loss: 0.0027\n",
      "Train Epoch: 9\t[60000/88956 (67%)]\tTotal Loss: 163.3202\tAvg Loss: 0.0027\n",
      "Train Epoch: 9\t[65000/88956 (73%)]\tTotal Loss: 176.4333\tAvg Loss: 0.0027\n",
      "Train Epoch: 9\t[70000/88956 (79%)]\tTotal Loss: 188.5522\tAvg Loss: 0.0027\n",
      "Train Epoch: 9\t[75000/88956 (84%)]\tTotal Loss: 201.1800\tAvg Loss: 0.0027\n",
      "Train Epoch: 9\t[80000/88956 (90%)]\tTotal Loss: 215.3500\tAvg Loss: 0.0027\n",
      "Train Epoch: 9\t[85000/88956 (96%)]\tTotal Loss: 228.4459\tAvg Loss: 0.0027\n",
      "====> Epoch: 9\tTotal Loss: 239.4494\t Avg Loss: 0.0027\t Fx Loss: 210.2534\t Set Loss: 29.1961\n",
      "\t\tCorrect: 19467/88956\tFx Correct: 76732/88956\tSet Correct: 21108/88956\n",
      "\t\tPercentage Correct: 21.88\tPercentage Fx Correct: 86.26\tPercentage Set Correct: 23.73\n",
      "====> Val Loss: 29.4531\t Avg Loss: 0.0030\t Fx Loss: 26.1226\t Set Loss: 3.3305\n",
      "\t\tCorrect: 2190/9885\tFx Correct: 8425/9885\tSet Correct: 2383/9885\n",
      "\t\tPercentage Correct: 22.15\tPercentage Fx Correct: 85.23\tPercentage Set Correct: 24.11\n",
      "====> Test Loss: 72.7634\t Avg Loss: 0.0029\t Fx Loss: 64.5551\t Set Loss: 8.2083\n",
      "\t\tCorrect: 5416/24711\tFx Correct: 21182/24711\tSet Correct: 5814/24711\n",
      "\t\tPercentage Correct: 21.92\tPercentage Fx Correct: 85.72\tPercentage Set Correct: 23.53\n",
      "\n",
      "=== saved best model ===\n",
      "\n",
      "Train Epoch: 10\t[5000/88956 (6%)]\tTotal Loss: 13.0918\tAvg Loss: 0.0026\n",
      "Train Epoch: 10\t[10000/88956 (11%)]\tTotal Loss: 26.8823\tAvg Loss: 0.0027\n",
      "Train Epoch: 10\t[15000/88956 (17%)]\tTotal Loss: 39.9795\tAvg Loss: 0.0027\n",
      "Train Epoch: 10\t[20000/88956 (22%)]\tTotal Loss: 53.3916\tAvg Loss: 0.0027\n",
      "Train Epoch: 10\t[25000/88956 (28%)]\tTotal Loss: 67.4127\tAvg Loss: 0.0027\n",
      "Train Epoch: 10\t[30000/88956 (34%)]\tTotal Loss: 80.4206\tAvg Loss: 0.0027\n",
      "Train Epoch: 10\t[35000/88956 (39%)]\tTotal Loss: 93.1754\tAvg Loss: 0.0027\n",
      "Train Epoch: 10\t[40000/88956 (45%)]\tTotal Loss: 106.9370\tAvg Loss: 0.0027\n",
      "Train Epoch: 10\t[45000/88956 (51%)]\tTotal Loss: 119.7176\tAvg Loss: 0.0027\n",
      "Train Epoch: 10\t[50000/88956 (56%)]\tTotal Loss: 132.5690\tAvg Loss: 0.0027\n",
      "Train Epoch: 10\t[55000/88956 (62%)]\tTotal Loss: 145.5316\tAvg Loss: 0.0026\n",
      "Train Epoch: 10\t[60000/88956 (67%)]\tTotal Loss: 158.1195\tAvg Loss: 0.0026\n",
      "Train Epoch: 10\t[65000/88956 (73%)]\tTotal Loss: 170.9785\tAvg Loss: 0.0026\n",
      "Train Epoch: 10\t[70000/88956 (79%)]\tTotal Loss: 184.3438\tAvg Loss: 0.0026\n",
      "Train Epoch: 10\t[75000/88956 (84%)]\tTotal Loss: 197.5619\tAvg Loss: 0.0026\n",
      "Train Epoch: 10\t[80000/88956 (90%)]\tTotal Loss: 211.9606\tAvg Loss: 0.0026\n",
      "Train Epoch: 10\t[85000/88956 (96%)]\tTotal Loss: 225.5513\tAvg Loss: 0.0027\n",
      "====> Epoch: 10\tTotal Loss: 235.9078\t Avg Loss: 0.0027\t Fx Loss: 207.2782\t Set Loss: 28.6296\n",
      "\t\tCorrect: 19736/88956\tFx Correct: 76772/88956\tSet Correct: 21460/88956\n",
      "\t\tPercentage Correct: 22.19\tPercentage Fx Correct: 86.30\tPercentage Set Correct: 24.12\n",
      "====> Val Loss: 25.8570\t Avg Loss: 0.0026\t Fx Loss: 22.6944\t Set Loss: 3.1626\n",
      "\t\tCorrect: 2215/9885\tFx Correct: 8520/9885\tSet Correct: 2395/9885\n",
      "\t\tPercentage Correct: 22.41\tPercentage Fx Correct: 86.19\tPercentage Set Correct: 24.23\n",
      "====> Test Loss: 64.7336\t Avg Loss: 0.0026\t Fx Loss: 56.9767\t Set Loss: 7.7569\n",
      "\t\tCorrect: 5563/24711\tFx Correct: 21428/24711\tSet Correct: 5974/24711\n",
      "\t\tPercentage Correct: 22.51\tPercentage Fx Correct: 86.71\tPercentage Set Correct: 24.18\n",
      "\n",
      "=== saved best model ===\n",
      "\n",
      "Train Epoch: 11\t[5000/88956 (6%)]\tTotal Loss: 11.8299\tAvg Loss: 0.0024\n",
      "Train Epoch: 11\t[10000/88956 (11%)]\tTotal Loss: 24.8928\tAvg Loss: 0.0025\n",
      "Train Epoch: 11\t[15000/88956 (17%)]\tTotal Loss: 38.0592\tAvg Loss: 0.0025\n",
      "Train Epoch: 11\t[20000/88956 (22%)]\tTotal Loss: 50.3236\tAvg Loss: 0.0025\n",
      "Train Epoch: 11\t[25000/88956 (28%)]\tTotal Loss: 64.3887\tAvg Loss: 0.0026\n",
      "Train Epoch: 11\t[30000/88956 (34%)]\tTotal Loss: 78.0407\tAvg Loss: 0.0026\n",
      "Train Epoch: 11\t[35000/88956 (39%)]\tTotal Loss: 91.4536\tAvg Loss: 0.0026\n",
      "Train Epoch: 11\t[40000/88956 (45%)]\tTotal Loss: 105.3754\tAvg Loss: 0.0026\n",
      "Train Epoch: 11\t[45000/88956 (51%)]\tTotal Loss: 117.4530\tAvg Loss: 0.0026\n",
      "Train Epoch: 11\t[50000/88956 (56%)]\tTotal Loss: 130.5875\tAvg Loss: 0.0026\n",
      "Train Epoch: 11\t[55000/88956 (62%)]\tTotal Loss: 143.5939\tAvg Loss: 0.0026\n",
      "Train Epoch: 11\t[60000/88956 (67%)]\tTotal Loss: 156.3815\tAvg Loss: 0.0026\n",
      "Train Epoch: 11\t[65000/88956 (73%)]\tTotal Loss: 168.8409\tAvg Loss: 0.0026\n",
      "Train Epoch: 11\t[70000/88956 (79%)]\tTotal Loss: 180.9994\tAvg Loss: 0.0026\n",
      "Train Epoch: 11\t[75000/88956 (84%)]\tTotal Loss: 194.0774\tAvg Loss: 0.0026\n",
      "Train Epoch: 11\t[80000/88956 (90%)]\tTotal Loss: 206.9453\tAvg Loss: 0.0026\n",
      "Train Epoch: 11\t[85000/88956 (96%)]\tTotal Loss: 219.8910\tAvg Loss: 0.0026\n",
      "====> Epoch: 11\tTotal Loss: 230.0562\t Avg Loss: 0.0026\t Fx Loss: 202.9574\t Set Loss: 27.0989\n",
      "\t\tCorrect: 20976/88956\tFx Correct: 76805/88956\tSet Correct: 22793/88956\n",
      "\t\tPercentage Correct: 23.58\tPercentage Fx Correct: 86.34\tPercentage Set Correct: 25.62\n",
      "====> Val Loss: 25.5986\t Avg Loss: 0.0026\t Fx Loss: 22.5052\t Set Loss: 3.0934\n",
      "\t\tCorrect: 2525/9885\tFx Correct: 8521/9885\tSet Correct: 2730/9885\n",
      "\t\tPercentage Correct: 25.54\tPercentage Fx Correct: 86.20\tPercentage Set Correct: 27.62\n",
      "====> Test Loss: 64.2416\t Avg Loss: 0.0026\t Fx Loss: 56.4038\t Set Loss: 7.8378\n",
      "\t\tCorrect: 6142/24711\tFx Correct: 21440/24711\tSet Correct: 6581/24711\n",
      "\t\tPercentage Correct: 24.86\tPercentage Fx Correct: 86.76\tPercentage Set Correct: 26.63\n",
      "\n",
      "=== saved best model ===\n",
      "\n",
      "Train Epoch: 12\t[5000/88956 (6%)]\tTotal Loss: 12.5743\tAvg Loss: 0.0025\n",
      "Train Epoch: 12\t[10000/88956 (11%)]\tTotal Loss: 24.5839\tAvg Loss: 0.0025\n",
      "Train Epoch: 12\t[15000/88956 (17%)]\tTotal Loss: 38.0243\tAvg Loss: 0.0025\n",
      "Train Epoch: 12\t[20000/88956 (22%)]\tTotal Loss: 51.3158\tAvg Loss: 0.0026\n",
      "Train Epoch: 12\t[25000/88956 (28%)]\tTotal Loss: 63.0855\tAvg Loss: 0.0025\n",
      "Train Epoch: 12\t[30000/88956 (34%)]\tTotal Loss: 75.3306\tAvg Loss: 0.0025\n",
      "Train Epoch: 12\t[35000/88956 (39%)]\tTotal Loss: 87.6438\tAvg Loss: 0.0025\n",
      "Train Epoch: 12\t[40000/88956 (45%)]\tTotal Loss: 99.6312\tAvg Loss: 0.0025\n",
      "Train Epoch: 12\t[45000/88956 (51%)]\tTotal Loss: 111.3159\tAvg Loss: 0.0025\n",
      "Train Epoch: 12\t[50000/88956 (56%)]\tTotal Loss: 123.2949\tAvg Loss: 0.0025\n",
      "Train Epoch: 12\t[55000/88956 (62%)]\tTotal Loss: 136.0554\tAvg Loss: 0.0025\n",
      "Train Epoch: 12\t[60000/88956 (67%)]\tTotal Loss: 148.7541\tAvg Loss: 0.0025\n",
      "Train Epoch: 12\t[65000/88956 (73%)]\tTotal Loss: 161.1552\tAvg Loss: 0.0025\n",
      "Train Epoch: 12\t[70000/88956 (79%)]\tTotal Loss: 172.8320\tAvg Loss: 0.0025\n",
      "Train Epoch: 12\t[75000/88956 (84%)]\tTotal Loss: 185.6786\tAvg Loss: 0.0025\n",
      "Train Epoch: 12\t[80000/88956 (90%)]\tTotal Loss: 198.7384\tAvg Loss: 0.0025\n",
      "Train Epoch: 12\t[85000/88956 (96%)]\tTotal Loss: 211.5147\tAvg Loss: 0.0025\n",
      "====> Epoch: 12\tTotal Loss: 221.3078\t Avg Loss: 0.0025\t Fx Loss: 195.3586\t Set Loss: 25.9492\n",
      "\t\tCorrect: 22383/88956\tFx Correct: 77157/88956\tSet Correct: 24229/88956\n",
      "\t\tPercentage Correct: 25.16\tPercentage Fx Correct: 86.74\tPercentage Set Correct: 27.24\n",
      "====> Val Loss: 24.8312\t Avg Loss: 0.0025\t Fx Loss: 21.9228\t Set Loss: 2.9084\n",
      "\t\tCorrect: 2560/9885\tFx Correct: 8591/9885\tSet Correct: 2772/9885\n",
      "\t\tPercentage Correct: 25.90\tPercentage Fx Correct: 86.91\tPercentage Set Correct: 28.04\n",
      "====> Test Loss: 63.4044\t Avg Loss: 0.0026\t Fx Loss: 56.0829\t Set Loss: 7.3215\n",
      "\t\tCorrect: 6238/24711\tFx Correct: 21305/24711\tSet Correct: 6807/24711\n",
      "\t\tPercentage Correct: 25.24\tPercentage Fx Correct: 86.22\tPercentage Set Correct: 27.55\n",
      "\n",
      "=== saved best model ===\n",
      "\n",
      "Train Epoch: 13\t[5000/88956 (6%)]\tTotal Loss: 12.2578\tAvg Loss: 0.0025\n",
      "Train Epoch: 13\t[10000/88956 (11%)]\tTotal Loss: 23.8898\tAvg Loss: 0.0024\n",
      "Train Epoch: 13\t[15000/88956 (17%)]\tTotal Loss: 35.7489\tAvg Loss: 0.0024\n",
      "Train Epoch: 13\t[20000/88956 (22%)]\tTotal Loss: 48.4209\tAvg Loss: 0.0024\n",
      "Train Epoch: 13\t[25000/88956 (28%)]\tTotal Loss: 61.8708\tAvg Loss: 0.0025\n",
      "Train Epoch: 13\t[30000/88956 (34%)]\tTotal Loss: 73.5858\tAvg Loss: 0.0025\n",
      "Train Epoch: 13\t[35000/88956 (39%)]\tTotal Loss: 85.2567\tAvg Loss: 0.0024\n",
      "Train Epoch: 13\t[40000/88956 (45%)]\tTotal Loss: 97.5537\tAvg Loss: 0.0024\n",
      "Train Epoch: 13\t[45000/88956 (51%)]\tTotal Loss: 110.1225\tAvg Loss: 0.0024\n",
      "Train Epoch: 13\t[50000/88956 (56%)]\tTotal Loss: 123.0295\tAvg Loss: 0.0025\n",
      "Train Epoch: 13\t[55000/88956 (62%)]\tTotal Loss: 135.9743\tAvg Loss: 0.0025\n",
      "Train Epoch: 13\t[60000/88956 (67%)]\tTotal Loss: 148.3116\tAvg Loss: 0.0025\n",
      "Train Epoch: 13\t[65000/88956 (73%)]\tTotal Loss: 161.1838\tAvg Loss: 0.0025\n",
      "Train Epoch: 13\t[70000/88956 (79%)]\tTotal Loss: 173.5996\tAvg Loss: 0.0025\n",
      "Train Epoch: 13\t[75000/88956 (84%)]\tTotal Loss: 185.6835\tAvg Loss: 0.0025\n",
      "Train Epoch: 13\t[80000/88956 (90%)]\tTotal Loss: 197.8558\tAvg Loss: 0.0025\n",
      "Train Epoch: 13\t[85000/88956 (96%)]\tTotal Loss: 209.7659\tAvg Loss: 0.0025\n",
      "====> Epoch: 13\tTotal Loss: 218.2409\t Avg Loss: 0.0025\t Fx Loss: 193.5054\t Set Loss: 24.7355\n",
      "\t\tCorrect: 23192/88956\tFx Correct: 77253/88956\tSet Correct: 25190/88956\n",
      "\t\tPercentage Correct: 26.07\tPercentage Fx Correct: 86.84\tPercentage Set Correct: 28.32\n",
      "====> Val Loss: 24.1567\t Avg Loss: 0.0024\t Fx Loss: 21.5339\t Set Loss: 2.6228\n",
      "\t\tCorrect: 2782/9885\tFx Correct: 8581/9885\tSet Correct: 3032/9885\n",
      "\t\tPercentage Correct: 28.14\tPercentage Fx Correct: 86.81\tPercentage Set Correct: 30.67\n",
      "====> Test Loss: 60.8296\t Avg Loss: 0.0025\t Fx Loss: 54.1821\t Set Loss: 6.6475\n",
      "\t\tCorrect: 6889/24711\tFx Correct: 21546/24711\tSet Correct: 7443/24711\n",
      "\t\tPercentage Correct: 27.88\tPercentage Fx Correct: 87.19\tPercentage Set Correct: 30.12\n",
      "\n",
      "=== saved best model ===\n",
      "\n",
      "Train Epoch: 14\t[5000/88956 (6%)]\tTotal Loss: 11.2809\tAvg Loss: 0.0023\n",
      "Train Epoch: 14\t[10000/88956 (11%)]\tTotal Loss: 23.2515\tAvg Loss: 0.0023\n",
      "Train Epoch: 14\t[15000/88956 (17%)]\tTotal Loss: 34.5530\tAvg Loss: 0.0023\n",
      "Train Epoch: 14\t[20000/88956 (22%)]\tTotal Loss: 45.9941\tAvg Loss: 0.0023\n",
      "Train Epoch: 14\t[25000/88956 (28%)]\tTotal Loss: 57.6624\tAvg Loss: 0.0023\n",
      "Train Epoch: 14\t[30000/88956 (34%)]\tTotal Loss: 69.3175\tAvg Loss: 0.0023\n",
      "Train Epoch: 14\t[35000/88956 (39%)]\tTotal Loss: 81.3970\tAvg Loss: 0.0023\n",
      "Train Epoch: 14\t[40000/88956 (45%)]\tTotal Loss: 93.7781\tAvg Loss: 0.0023\n",
      "Train Epoch: 14\t[45000/88956 (51%)]\tTotal Loss: 106.2704\tAvg Loss: 0.0024\n",
      "Train Epoch: 14\t[50000/88956 (56%)]\tTotal Loss: 117.9715\tAvg Loss: 0.0024\n",
      "Train Epoch: 14\t[55000/88956 (62%)]\tTotal Loss: 129.9119\tAvg Loss: 0.0024\n",
      "Train Epoch: 14\t[60000/88956 (67%)]\tTotal Loss: 142.8467\tAvg Loss: 0.0024\n",
      "Train Epoch: 14\t[65000/88956 (73%)]\tTotal Loss: 155.4655\tAvg Loss: 0.0024\n",
      "Train Epoch: 14\t[70000/88956 (79%)]\tTotal Loss: 167.8516\tAvg Loss: 0.0024\n",
      "Train Epoch: 14\t[75000/88956 (84%)]\tTotal Loss: 180.6151\tAvg Loss: 0.0024\n",
      "Train Epoch: 14\t[80000/88956 (90%)]\tTotal Loss: 192.0356\tAvg Loss: 0.0024\n",
      "Train Epoch: 14\t[85000/88956 (96%)]\tTotal Loss: 203.7409\tAvg Loss: 0.0024\n",
      "====> Epoch: 14\tTotal Loss: 212.6319\t Avg Loss: 0.0024\t Fx Loss: 188.4006\t Set Loss: 24.2312\n",
      "\t\tCorrect: 23771/88956\tFx Correct: 77366/88956\tSet Correct: 25772/88956\n",
      "\t\tPercentage Correct: 26.72\tPercentage Fx Correct: 86.97\tPercentage Set Correct: 28.97\n",
      "====> Val Loss: 27.7667\t Avg Loss: 0.0028\t Fx Loss: 24.3830\t Set Loss: 3.3837\n",
      "\t\tCorrect: 2315/9885\tFx Correct: 8508/9885\tSet Correct: 2501/9885\n",
      "\t\tPercentage Correct: 23.42\tPercentage Fx Correct: 86.07\tPercentage Set Correct: 25.30\n",
      "====> Test Loss: 70.1157\t Avg Loss: 0.0028\t Fx Loss: 61.4662\t Set Loss: 8.6496\n",
      "\t\tCorrect: 5648/24711\tFx Correct: 21145/24711\tSet Correct: 6143/24711\n",
      "\t\tPercentage Correct: 22.86\tPercentage Fx Correct: 85.57\tPercentage Set Correct: 24.86\n",
      "Train Epoch: 15\t[5000/88956 (6%)]\tTotal Loss: 11.4758\tAvg Loss: 0.0023\n",
      "Train Epoch: 15\t[10000/88956 (11%)]\tTotal Loss: 23.4290\tAvg Loss: 0.0023\n",
      "Train Epoch: 15\t[15000/88956 (17%)]\tTotal Loss: 34.9720\tAvg Loss: 0.0023\n",
      "Train Epoch: 15\t[20000/88956 (22%)]\tTotal Loss: 46.7823\tAvg Loss: 0.0023\n",
      "Train Epoch: 15\t[25000/88956 (28%)]\tTotal Loss: 58.6888\tAvg Loss: 0.0023\n",
      "Train Epoch: 15\t[30000/88956 (34%)]\tTotal Loss: 70.7980\tAvg Loss: 0.0024\n",
      "Train Epoch: 15\t[35000/88956 (39%)]\tTotal Loss: 82.8120\tAvg Loss: 0.0024\n",
      "Train Epoch: 15\t[40000/88956 (45%)]\tTotal Loss: 94.6684\tAvg Loss: 0.0024\n",
      "Train Epoch: 15\t[45000/88956 (51%)]\tTotal Loss: 106.5665\tAvg Loss: 0.0024\n",
      "Train Epoch: 15\t[50000/88956 (56%)]\tTotal Loss: 118.7991\tAvg Loss: 0.0024\n",
      "Train Epoch: 15\t[55000/88956 (62%)]\tTotal Loss: 130.8474\tAvg Loss: 0.0024\n",
      "Train Epoch: 15\t[60000/88956 (67%)]\tTotal Loss: 142.8188\tAvg Loss: 0.0024\n",
      "Train Epoch: 15\t[65000/88956 (73%)]\tTotal Loss: 154.3426\tAvg Loss: 0.0024\n",
      "Train Epoch: 15\t[70000/88956 (79%)]\tTotal Loss: 165.9189\tAvg Loss: 0.0024\n",
      "Train Epoch: 15\t[75000/88956 (84%)]\tTotal Loss: 178.2820\tAvg Loss: 0.0024\n",
      "Train Epoch: 15\t[80000/88956 (90%)]\tTotal Loss: 190.6501\tAvg Loss: 0.0024\n",
      "Train Epoch: 15\t[85000/88956 (96%)]\tTotal Loss: 202.9038\tAvg Loss: 0.0024\n",
      "====> Epoch: 15\tTotal Loss: 211.3300\t Avg Loss: 0.0024\t Fx Loss: 187.9545\t Set Loss: 23.3755\n",
      "\t\tCorrect: 24397/88956\tFx Correct: 77381/88956\tSet Correct: 26479/88956\n",
      "\t\tPercentage Correct: 27.43\tPercentage Fx Correct: 86.99\tPercentage Set Correct: 29.77\n",
      "====> Val Loss: 24.3432\t Avg Loss: 0.0025\t Fx Loss: 21.7497\t Set Loss: 2.5936\n",
      "\t\tCorrect: 2830/9885\tFx Correct: 8555/9885\tSet Correct: 3034/9885\n",
      "\t\tPercentage Correct: 28.63\tPercentage Fx Correct: 86.55\tPercentage Set Correct: 30.69\n",
      "====> Test Loss: 60.2194\t Avg Loss: 0.0024\t Fx Loss: 53.7288\t Set Loss: 6.4905\n",
      "\t\tCorrect: 7220/24711\tFx Correct: 21559/24711\tSet Correct: 7741/24711\n",
      "\t\tPercentage Correct: 29.22\tPercentage Fx Correct: 87.24\tPercentage Set Correct: 31.33\n",
      "\n",
      "=== saved best model ===\n",
      "\n",
      "Train Epoch: 16\t[5000/88956 (6%)]\tTotal Loss: 11.3230\tAvg Loss: 0.0023\n",
      "Train Epoch: 16\t[10000/88956 (11%)]\tTotal Loss: 22.6105\tAvg Loss: 0.0023\n",
      "Train Epoch: 16\t[15000/88956 (17%)]\tTotal Loss: 34.0739\tAvg Loss: 0.0023\n",
      "Train Epoch: 16\t[20000/88956 (22%)]\tTotal Loss: 47.8582\tAvg Loss: 0.0024\n",
      "Train Epoch: 16\t[25000/88956 (28%)]\tTotal Loss: 60.5203\tAvg Loss: 0.0024\n",
      "Train Epoch: 16\t[30000/88956 (34%)]\tTotal Loss: 71.9073\tAvg Loss: 0.0024\n",
      "Train Epoch: 16\t[35000/88956 (39%)]\tTotal Loss: 83.3016\tAvg Loss: 0.0024\n",
      "Train Epoch: 16\t[40000/88956 (45%)]\tTotal Loss: 95.4461\tAvg Loss: 0.0024\n",
      "Train Epoch: 16\t[45000/88956 (51%)]\tTotal Loss: 106.7509\tAvg Loss: 0.0024\n",
      "Train Epoch: 16\t[50000/88956 (56%)]\tTotal Loss: 117.8630\tAvg Loss: 0.0024\n",
      "Train Epoch: 16\t[55000/88956 (62%)]\tTotal Loss: 130.5927\tAvg Loss: 0.0024\n",
      "Train Epoch: 16\t[60000/88956 (67%)]\tTotal Loss: 141.7960\tAvg Loss: 0.0024\n",
      "Train Epoch: 16\t[65000/88956 (73%)]\tTotal Loss: 153.5742\tAvg Loss: 0.0024\n",
      "Train Epoch: 16\t[70000/88956 (79%)]\tTotal Loss: 165.4686\tAvg Loss: 0.0024\n",
      "Train Epoch: 16\t[75000/88956 (84%)]\tTotal Loss: 176.7743\tAvg Loss: 0.0024\n",
      "Train Epoch: 16\t[80000/88956 (90%)]\tTotal Loss: 188.2851\tAvg Loss: 0.0024\n",
      "Train Epoch: 16\t[85000/88956 (96%)]\tTotal Loss: 199.4670\tAvg Loss: 0.0023\n",
      "====> Epoch: 16\tTotal Loss: 208.2301\t Avg Loss: 0.0023\t Fx Loss: 185.7077\t Set Loss: 22.5225\n",
      "\t\tCorrect: 25430/88956\tFx Correct: 77517/88956\tSet Correct: 27608/88956\n",
      "\t\tPercentage Correct: 28.59\tPercentage Fx Correct: 87.14\tPercentage Set Correct: 31.04\n",
      "====> Val Loss: 23.0533\t Avg Loss: 0.0023\t Fx Loss: 20.5867\t Set Loss: 2.4666\n",
      "\t\tCorrect: 3010/9885\tFx Correct: 8622/9885\tSet Correct: 3280/9885\n",
      "\t\tPercentage Correct: 30.45\tPercentage Fx Correct: 87.22\tPercentage Set Correct: 33.18\n",
      "====> Test Loss: 57.8661\t Avg Loss: 0.0023\t Fx Loss: 51.7613\t Set Loss: 6.1047\n",
      "\t\tCorrect: 7508/24711\tFx Correct: 21471/24711\tSet Correct: 8202/24711\n",
      "\t\tPercentage Correct: 30.38\tPercentage Fx Correct: 86.89\tPercentage Set Correct: 33.19\n",
      "\n",
      "=== saved best model ===\n",
      "\n",
      "Train Epoch: 17\t[5000/88956 (6%)]\tTotal Loss: 11.9292\tAvg Loss: 0.0024\n",
      "Train Epoch: 17\t[10000/88956 (11%)]\tTotal Loss: 22.7920\tAvg Loss: 0.0023\n",
      "Train Epoch: 17\t[15000/88956 (17%)]\tTotal Loss: 33.3218\tAvg Loss: 0.0022\n",
      "Train Epoch: 17\t[20000/88956 (22%)]\tTotal Loss: 44.8283\tAvg Loss: 0.0022\n",
      "Train Epoch: 17\t[25000/88956 (28%)]\tTotal Loss: 55.8977\tAvg Loss: 0.0022\n",
      "Train Epoch: 17\t[30000/88956 (34%)]\tTotal Loss: 66.8605\tAvg Loss: 0.0022\n",
      "Train Epoch: 17\t[35000/88956 (39%)]\tTotal Loss: 78.1652\tAvg Loss: 0.0022\n",
      "Train Epoch: 17\t[40000/88956 (45%)]\tTotal Loss: 90.1876\tAvg Loss: 0.0023\n",
      "Train Epoch: 17\t[45000/88956 (51%)]\tTotal Loss: 102.2347\tAvg Loss: 0.0023\n",
      "Train Epoch: 17\t[50000/88956 (56%)]\tTotal Loss: 114.3236\tAvg Loss: 0.0023\n",
      "Train Epoch: 17\t[55000/88956 (62%)]\tTotal Loss: 126.1675\tAvg Loss: 0.0023\n",
      "Train Epoch: 17\t[60000/88956 (67%)]\tTotal Loss: 138.0767\tAvg Loss: 0.0023\n",
      "Train Epoch: 17\t[65000/88956 (73%)]\tTotal Loss: 149.3661\tAvg Loss: 0.0023\n",
      "Train Epoch: 17\t[70000/88956 (79%)]\tTotal Loss: 161.4400\tAvg Loss: 0.0023\n",
      "Train Epoch: 17\t[75000/88956 (84%)]\tTotal Loss: 174.2259\tAvg Loss: 0.0023\n",
      "Train Epoch: 17\t[80000/88956 (90%)]\tTotal Loss: 186.3042\tAvg Loss: 0.0023\n",
      "Train Epoch: 17\t[85000/88956 (96%)]\tTotal Loss: 197.7961\tAvg Loss: 0.0023\n",
      "====> Epoch: 17\tTotal Loss: 207.4454\t Avg Loss: 0.0023\t Fx Loss: 184.8597\t Set Loss: 22.5857\n",
      "\t\tCorrect: 25699/88956\tFx Correct: 77392/88956\tSet Correct: 27827/88956\n",
      "\t\tPercentage Correct: 28.89\tPercentage Fx Correct: 87.00\tPercentage Set Correct: 31.28\n",
      "====> Val Loss: 24.7276\t Avg Loss: 0.0025\t Fx Loss: 22.1131\t Set Loss: 2.6145\n",
      "\t\tCorrect: 2748/9885\tFx Correct: 8538/9885\tSet Correct: 3005/9885\n",
      "\t\tPercentage Correct: 27.80\tPercentage Fx Correct: 86.37\tPercentage Set Correct: 30.40\n",
      "====> Test Loss: 61.3572\t Avg Loss: 0.0025\t Fx Loss: 54.8274\t Set Loss: 6.5298\n",
      "\t\tCorrect: 6777/24711\tFx Correct: 21501/24711\tSet Correct: 7360/24711\n",
      "\t\tPercentage Correct: 27.43\tPercentage Fx Correct: 87.01\tPercentage Set Correct: 29.78\n",
      "Train Epoch: 18\t[5000/88956 (6%)]\tTotal Loss: 11.8272\tAvg Loss: 0.0024\n",
      "Train Epoch: 18\t[10000/88956 (11%)]\tTotal Loss: 23.1409\tAvg Loss: 0.0023\n",
      "Train Epoch: 18\t[15000/88956 (17%)]\tTotal Loss: 34.1612\tAvg Loss: 0.0023\n",
      "Train Epoch: 18\t[20000/88956 (22%)]\tTotal Loss: 44.9321\tAvg Loss: 0.0022\n",
      "Train Epoch: 18\t[25000/88956 (28%)]\tTotal Loss: 56.1107\tAvg Loss: 0.0022\n",
      "Train Epoch: 18\t[30000/88956 (34%)]\tTotal Loss: 66.9469\tAvg Loss: 0.0022\n",
      "Train Epoch: 18\t[35000/88956 (39%)]\tTotal Loss: 78.2988\tAvg Loss: 0.0022\n",
      "Train Epoch: 18\t[40000/88956 (45%)]\tTotal Loss: 89.1916\tAvg Loss: 0.0022\n",
      "Train Epoch: 18\t[45000/88956 (51%)]\tTotal Loss: 100.7661\tAvg Loss: 0.0022\n",
      "Train Epoch: 18\t[50000/88956 (56%)]\tTotal Loss: 112.8983\tAvg Loss: 0.0023\n",
      "Train Epoch: 18\t[55000/88956 (62%)]\tTotal Loss: 124.0929\tAvg Loss: 0.0023\n",
      "Train Epoch: 18\t[60000/88956 (67%)]\tTotal Loss: 135.7186\tAvg Loss: 0.0023\n",
      "Train Epoch: 18\t[65000/88956 (73%)]\tTotal Loss: 147.6120\tAvg Loss: 0.0023\n",
      "Train Epoch: 18\t[70000/88956 (79%)]\tTotal Loss: 159.6201\tAvg Loss: 0.0023\n",
      "Train Epoch: 18\t[75000/88956 (84%)]\tTotal Loss: 170.7469\tAvg Loss: 0.0023\n",
      "Train Epoch: 18\t[80000/88956 (90%)]\tTotal Loss: 182.4319\tAvg Loss: 0.0023\n",
      "Train Epoch: 18\t[85000/88956 (96%)]\tTotal Loss: 194.2824\tAvg Loss: 0.0023\n",
      "====> Epoch: 18\tTotal Loss: 202.9126\t Avg Loss: 0.0023\t Fx Loss: 181.2290\t Set Loss: 21.6835\n",
      "\t\tCorrect: 26379/88956\tFx Correct: 77551/88956\tSet Correct: 28623/88956\n",
      "\t\tPercentage Correct: 29.65\tPercentage Fx Correct: 87.18\tPercentage Set Correct: 32.18\n",
      "====> Val Loss: 22.9333\t Avg Loss: 0.0023\t Fx Loss: 20.4559\t Set Loss: 2.4774\n",
      "\t\tCorrect: 2830/9885\tFx Correct: 8600/9885\tSet Correct: 3099/9885\n",
      "\t\tPercentage Correct: 28.63\tPercentage Fx Correct: 87.00\tPercentage Set Correct: 31.35\n",
      "====> Test Loss: 57.1207\t Avg Loss: 0.0023\t Fx Loss: 50.8947\t Set Loss: 6.2260\n",
      "\t\tCorrect: 7207/24711\tFx Correct: 21619/24711\tSet Correct: 7756/24711\n",
      "\t\tPercentage Correct: 29.17\tPercentage Fx Correct: 87.49\tPercentage Set Correct: 31.39\n",
      "Train Epoch: 19\t[5000/88956 (6%)]\tTotal Loss: 10.8683\tAvg Loss: 0.0022\n",
      "Train Epoch: 19\t[10000/88956 (11%)]\tTotal Loss: 21.5673\tAvg Loss: 0.0022\n",
      "Train Epoch: 19\t[15000/88956 (17%)]\tTotal Loss: 32.3041\tAvg Loss: 0.0022\n",
      "Train Epoch: 19\t[20000/88956 (22%)]\tTotal Loss: 43.3010\tAvg Loss: 0.0022\n",
      "Train Epoch: 19\t[25000/88956 (28%)]\tTotal Loss: 54.4137\tAvg Loss: 0.0022\n",
      "Train Epoch: 19\t[30000/88956 (34%)]\tTotal Loss: 65.7131\tAvg Loss: 0.0022\n",
      "Train Epoch: 19\t[35000/88956 (39%)]\tTotal Loss: 76.7506\tAvg Loss: 0.0022\n",
      "Train Epoch: 19\t[40000/88956 (45%)]\tTotal Loss: 87.9296\tAvg Loss: 0.0022\n",
      "Train Epoch: 19\t[45000/88956 (51%)]\tTotal Loss: 99.1355\tAvg Loss: 0.0022\n",
      "Train Epoch: 19\t[50000/88956 (56%)]\tTotal Loss: 111.4546\tAvg Loss: 0.0022\n",
      "Train Epoch: 19\t[55000/88956 (62%)]\tTotal Loss: 122.5311\tAvg Loss: 0.0022\n",
      "Train Epoch: 19\t[60000/88956 (67%)]\tTotal Loss: 133.2634\tAvg Loss: 0.0022\n",
      "Train Epoch: 19\t[65000/88956 (73%)]\tTotal Loss: 144.0443\tAvg Loss: 0.0022\n",
      "Train Epoch: 19\t[70000/88956 (79%)]\tTotal Loss: 155.4546\tAvg Loss: 0.0022\n",
      "Train Epoch: 19\t[75000/88956 (84%)]\tTotal Loss: 166.1212\tAvg Loss: 0.0022\n",
      "Train Epoch: 19\t[80000/88956 (90%)]\tTotal Loss: 176.9224\tAvg Loss: 0.0022\n",
      "Train Epoch: 19\t[85000/88956 (96%)]\tTotal Loss: 187.6160\tAvg Loss: 0.0022\n",
      "====> Epoch: 19\tTotal Loss: 197.1376\t Avg Loss: 0.0022\t Fx Loss: 176.3527\t Set Loss: 20.7849\n",
      "\t\tCorrect: 27581/88956\tFx Correct: 77914/88956\tSet Correct: 29861/88956\n",
      "\t\tPercentage Correct: 31.01\tPercentage Fx Correct: 87.59\tPercentage Set Correct: 33.57\n",
      "====> Val Loss: 23.5925\t Avg Loss: 0.0024\t Fx Loss: 21.2722\t Set Loss: 2.3204\n",
      "\t\tCorrect: 3039/9885\tFx Correct: 8614/9885\tSet Correct: 3303/9885\n",
      "\t\tPercentage Correct: 30.74\tPercentage Fx Correct: 87.14\tPercentage Set Correct: 33.41\n",
      "====> Test Loss: 58.2163\t Avg Loss: 0.0024\t Fx Loss: 52.3412\t Set Loss: 5.8752\n",
      "\t\tCorrect: 7581/24711\tFx Correct: 21427/24711\tSet Correct: 8273/24711\n",
      "\t\tPercentage Correct: 30.68\tPercentage Fx Correct: 86.71\tPercentage Set Correct: 33.48\n",
      "\n",
      "=== saved best model ===\n",
      "\n",
      "Train Epoch: 20\t[5000/88956 (6%)]\tTotal Loss: 11.4346\tAvg Loss: 0.0023\n",
      "Train Epoch: 20\t[10000/88956 (11%)]\tTotal Loss: 22.5191\tAvg Loss: 0.0023\n",
      "Train Epoch: 20\t[15000/88956 (17%)]\tTotal Loss: 33.3593\tAvg Loss: 0.0022\n",
      "Train Epoch: 20\t[20000/88956 (22%)]\tTotal Loss: 44.3267\tAvg Loss: 0.0022\n",
      "Train Epoch: 20\t[25000/88956 (28%)]\tTotal Loss: 55.4524\tAvg Loss: 0.0022\n",
      "Train Epoch: 20\t[30000/88956 (34%)]\tTotal Loss: 66.5215\tAvg Loss: 0.0022\n",
      "Train Epoch: 20\t[35000/88956 (39%)]\tTotal Loss: 76.8841\tAvg Loss: 0.0022\n",
      "Train Epoch: 20\t[40000/88956 (45%)]\tTotal Loss: 87.7352\tAvg Loss: 0.0022\n",
      "Train Epoch: 20\t[45000/88956 (51%)]\tTotal Loss: 99.7235\tAvg Loss: 0.0022\n",
      "Train Epoch: 20\t[50000/88956 (56%)]\tTotal Loss: 110.7451\tAvg Loss: 0.0022\n",
      "Train Epoch: 20\t[55000/88956 (62%)]\tTotal Loss: 122.0130\tAvg Loss: 0.0022\n",
      "Train Epoch: 20\t[60000/88956 (67%)]\tTotal Loss: 133.2612\tAvg Loss: 0.0022\n",
      "Train Epoch: 20\t[65000/88956 (73%)]\tTotal Loss: 144.1481\tAvg Loss: 0.0022\n",
      "Train Epoch: 20\t[70000/88956 (79%)]\tTotal Loss: 155.5387\tAvg Loss: 0.0022\n",
      "Train Epoch: 20\t[75000/88956 (84%)]\tTotal Loss: 166.5366\tAvg Loss: 0.0022\n",
      "Train Epoch: 20\t[80000/88956 (90%)]\tTotal Loss: 177.2605\tAvg Loss: 0.0022\n",
      "Train Epoch: 20\t[85000/88956 (96%)]\tTotal Loss: 187.4517\tAvg Loss: 0.0022\n",
      "====> Epoch: 20\tTotal Loss: 196.4767\t Avg Loss: 0.0022\t Fx Loss: 175.9929\t Set Loss: 20.4838\n",
      "\t\tCorrect: 27549/88956\tFx Correct: 77899/88956\tSet Correct: 29876/88956\n",
      "\t\tPercentage Correct: 30.97\tPercentage Fx Correct: 87.57\tPercentage Set Correct: 33.59\n",
      "====> Val Loss: 23.1683\t Avg Loss: 0.0023\t Fx Loss: 20.8625\t Set Loss: 2.3058\n",
      "\t\tCorrect: 3117/9885\tFx Correct: 8600/9885\tSet Correct: 3402/9885\n",
      "\t\tPercentage Correct: 31.53\tPercentage Fx Correct: 87.00\tPercentage Set Correct: 34.42\n",
      "====> Test Loss: 58.1854\t Avg Loss: 0.0024\t Fx Loss: 52.2952\t Set Loss: 5.8902\n",
      "\t\tCorrect: 7739/24711\tFx Correct: 21604/24711\tSet Correct: 8394/24711\n",
      "\t\tPercentage Correct: 31.32\tPercentage Fx Correct: 87.43\tPercentage Set Correct: 33.97\n",
      "\n",
      "=== saved best model ===\n",
      "\n",
      "Train Epoch: 21\t[5000/88956 (6%)]\tTotal Loss: 11.2155\tAvg Loss: 0.0022\n",
      "Train Epoch: 21\t[10000/88956 (11%)]\tTotal Loss: 21.9388\tAvg Loss: 0.0022\n",
      "Train Epoch: 21\t[15000/88956 (17%)]\tTotal Loss: 32.0857\tAvg Loss: 0.0021\n",
      "Train Epoch: 21\t[20000/88956 (22%)]\tTotal Loss: 44.2288\tAvg Loss: 0.0022\n",
      "Train Epoch: 21\t[25000/88956 (28%)]\tTotal Loss: 55.3604\tAvg Loss: 0.0022\n",
      "Train Epoch: 21\t[30000/88956 (34%)]\tTotal Loss: 65.8360\tAvg Loss: 0.0022\n",
      "Train Epoch: 21\t[35000/88956 (39%)]\tTotal Loss: 76.5327\tAvg Loss: 0.0022\n",
      "Train Epoch: 21\t[40000/88956 (45%)]\tTotal Loss: 87.1171\tAvg Loss: 0.0022\n",
      "Train Epoch: 21\t[45000/88956 (51%)]\tTotal Loss: 97.9638\tAvg Loss: 0.0022\n",
      "Train Epoch: 21\t[50000/88956 (56%)]\tTotal Loss: 108.3135\tAvg Loss: 0.0022\n",
      "Train Epoch: 21\t[55000/88956 (62%)]\tTotal Loss: 119.4100\tAvg Loss: 0.0022\n",
      "Train Epoch: 21\t[60000/88956 (67%)]\tTotal Loss: 130.3424\tAvg Loss: 0.0022\n",
      "Train Epoch: 21\t[65000/88956 (73%)]\tTotal Loss: 141.3369\tAvg Loss: 0.0022\n",
      "Train Epoch: 21\t[70000/88956 (79%)]\tTotal Loss: 152.3562\tAvg Loss: 0.0022\n",
      "Train Epoch: 21\t[75000/88956 (84%)]\tTotal Loss: 163.3998\tAvg Loss: 0.0022\n",
      "Train Epoch: 21\t[80000/88956 (90%)]\tTotal Loss: 173.9570\tAvg Loss: 0.0022\n",
      "Train Epoch: 21\t[85000/88956 (96%)]\tTotal Loss: 184.8656\tAvg Loss: 0.0022\n",
      "====> Epoch: 21\tTotal Loss: 193.5065\t Avg Loss: 0.0022\t Fx Loss: 173.6477\t Set Loss: 19.8588\n",
      "\t\tCorrect: 28549/88956\tFx Correct: 77999/88956\tSet Correct: 31024/88956\n",
      "\t\tPercentage Correct: 32.09\tPercentage Fx Correct: 87.68\tPercentage Set Correct: 34.88\n",
      "====> Val Loss: 23.1920\t Avg Loss: 0.0023\t Fx Loss: 20.8832\t Set Loss: 2.3088\n",
      "\t\tCorrect: 3238/9885\tFx Correct: 8626/9885\tSet Correct: 3513/9885\n",
      "\t\tPercentage Correct: 32.76\tPercentage Fx Correct: 87.26\tPercentage Set Correct: 35.54\n",
      "====> Test Loss: 58.9211\t Avg Loss: 0.0024\t Fx Loss: 53.0956\t Set Loss: 5.8255\n",
      "\t\tCorrect: 7963/24711\tFx Correct: 21455/24711\tSet Correct: 8718/24711\n",
      "\t\tPercentage Correct: 32.22\tPercentage Fx Correct: 86.82\tPercentage Set Correct: 35.28\n",
      "\n",
      "=== saved best model ===\n",
      "\n",
      "Train Epoch: 22\t[5000/88956 (6%)]\tTotal Loss: 11.3154\tAvg Loss: 0.0023\n",
      "Train Epoch: 22\t[10000/88956 (11%)]\tTotal Loss: 21.9017\tAvg Loss: 0.0022\n",
      "Train Epoch: 22\t[15000/88956 (17%)]\tTotal Loss: 33.0532\tAvg Loss: 0.0022\n",
      "Train Epoch: 22\t[20000/88956 (22%)]\tTotal Loss: 45.0323\tAvg Loss: 0.0023\n",
      "Train Epoch: 22\t[25000/88956 (28%)]\tTotal Loss: 55.7847\tAvg Loss: 0.0022\n",
      "Train Epoch: 22\t[30000/88956 (34%)]\tTotal Loss: 66.4908\tAvg Loss: 0.0022\n",
      "Train Epoch: 22\t[35000/88956 (39%)]\tTotal Loss: 77.4688\tAvg Loss: 0.0022\n",
      "Train Epoch: 22\t[40000/88956 (45%)]\tTotal Loss: 88.1892\tAvg Loss: 0.0022\n",
      "Train Epoch: 22\t[45000/88956 (51%)]\tTotal Loss: 99.0690\tAvg Loss: 0.0022\n",
      "Train Epoch: 22\t[50000/88956 (56%)]\tTotal Loss: 110.4921\tAvg Loss: 0.0022\n",
      "Train Epoch: 22\t[55000/88956 (62%)]\tTotal Loss: 121.8247\tAvg Loss: 0.0022\n",
      "Train Epoch: 22\t[60000/88956 (67%)]\tTotal Loss: 132.5082\tAvg Loss: 0.0022\n",
      "Train Epoch: 22\t[65000/88956 (73%)]\tTotal Loss: 142.7462\tAvg Loss: 0.0022\n",
      "Train Epoch: 22\t[70000/88956 (79%)]\tTotal Loss: 152.5296\tAvg Loss: 0.0022\n",
      "Train Epoch: 22\t[75000/88956 (84%)]\tTotal Loss: 163.7904\tAvg Loss: 0.0022\n",
      "Train Epoch: 22\t[80000/88956 (90%)]\tTotal Loss: 175.1708\tAvg Loss: 0.0022\n",
      "Train Epoch: 22\t[85000/88956 (96%)]\tTotal Loss: 186.6604\tAvg Loss: 0.0022\n",
      "====> Epoch: 22\tTotal Loss: 194.9156\t Avg Loss: 0.0022\t Fx Loss: 175.2095\t Set Loss: 19.7061\n",
      "\t\tCorrect: 28738/88956\tFx Correct: 77839/88956\tSet Correct: 31145/88956\n",
      "\t\tPercentage Correct: 32.31\tPercentage Fx Correct: 87.50\tPercentage Set Correct: 35.01\n",
      "====> Val Loss: 25.5591\t Avg Loss: 0.0026\t Fx Loss: 22.6855\t Set Loss: 2.8736\n",
      "\t\tCorrect: 2966/9885\tFx Correct: 8553/9885\tSet Correct: 3202/9885\n",
      "\t\tPercentage Correct: 30.01\tPercentage Fx Correct: 86.53\tPercentage Set Correct: 32.39\n",
      "====> Test Loss: 64.0562\t Avg Loss: 0.0026\t Fx Loss: 56.7971\t Set Loss: 7.2591\n",
      "\t\tCorrect: 7751/24711\tFx Correct: 21505/24711\tSet Correct: 8313/24711\n",
      "\t\tPercentage Correct: 31.37\tPercentage Fx Correct: 87.03\tPercentage Set Correct: 33.64\n",
      "Train Epoch: 23\t[5000/88956 (6%)]\tTotal Loss: 11.3523\tAvg Loss: 0.0023\n",
      "Train Epoch: 23\t[10000/88956 (11%)]\tTotal Loss: 21.5328\tAvg Loss: 0.0022\n",
      "Train Epoch: 23\t[15000/88956 (17%)]\tTotal Loss: 32.0617\tAvg Loss: 0.0021\n",
      "Train Epoch: 23\t[20000/88956 (22%)]\tTotal Loss: 42.2905\tAvg Loss: 0.0021\n",
      "Train Epoch: 23\t[25000/88956 (28%)]\tTotal Loss: 52.4294\tAvg Loss: 0.0021\n",
      "Train Epoch: 23\t[30000/88956 (34%)]\tTotal Loss: 62.1837\tAvg Loss: 0.0021\n",
      "Train Epoch: 23\t[35000/88956 (39%)]\tTotal Loss: 72.5455\tAvg Loss: 0.0021\n",
      "Train Epoch: 23\t[40000/88956 (45%)]\tTotal Loss: 83.9791\tAvg Loss: 0.0021\n",
      "Train Epoch: 23\t[45000/88956 (51%)]\tTotal Loss: 94.7400\tAvg Loss: 0.0021\n",
      "Train Epoch: 23\t[50000/88956 (56%)]\tTotal Loss: 106.1554\tAvg Loss: 0.0021\n",
      "Train Epoch: 23\t[55000/88956 (62%)]\tTotal Loss: 117.1640\tAvg Loss: 0.0021\n",
      "Train Epoch: 23\t[60000/88956 (67%)]\tTotal Loss: 128.0986\tAvg Loss: 0.0021\n",
      "Train Epoch: 23\t[65000/88956 (73%)]\tTotal Loss: 138.2039\tAvg Loss: 0.0021\n",
      "Train Epoch: 23\t[70000/88956 (79%)]\tTotal Loss: 148.9920\tAvg Loss: 0.0021\n",
      "Train Epoch: 23\t[75000/88956 (84%)]\tTotal Loss: 160.2158\tAvg Loss: 0.0021\n",
      "Train Epoch: 23\t[80000/88956 (90%)]\tTotal Loss: 170.2086\tAvg Loss: 0.0021\n",
      "Train Epoch: 23\t[85000/88956 (96%)]\tTotal Loss: 181.1342\tAvg Loss: 0.0021\n",
      "====> Epoch: 23\tTotal Loss: 189.6022\t Avg Loss: 0.0021\t Fx Loss: 170.4664\t Set Loss: 19.1358\n",
      "\t\tCorrect: 29195/88956\tFx Correct: 78263/88956\tSet Correct: 31567/88956\n",
      "\t\tPercentage Correct: 32.82\tPercentage Fx Correct: 87.98\tPercentage Set Correct: 35.49\n",
      "====> Val Loss: 23.0573\t Avg Loss: 0.0023\t Fx Loss: 20.8466\t Set Loss: 2.2107\n",
      "\t\tCorrect: 3220/9885\tFx Correct: 8620/9885\tSet Correct: 3519/9885\n",
      "\t\tPercentage Correct: 32.57\tPercentage Fx Correct: 87.20\tPercentage Set Correct: 35.60\n",
      "====> Test Loss: 57.1473\t Avg Loss: 0.0023\t Fx Loss: 51.5016\t Set Loss: 5.6457\n",
      "\t\tCorrect: 8279/24711\tFx Correct: 21459/24711\tSet Correct: 9102/24711\n",
      "\t\tPercentage Correct: 33.50\tPercentage Fx Correct: 86.84\tPercentage Set Correct: 36.83\n",
      "Train Epoch: 24\t[5000/88956 (6%)]\tTotal Loss: 11.0707\tAvg Loss: 0.0022\n",
      "Train Epoch: 24\t[10000/88956 (11%)]\tTotal Loss: 21.3236\tAvg Loss: 0.0021\n",
      "Train Epoch: 24\t[15000/88956 (17%)]\tTotal Loss: 31.2650\tAvg Loss: 0.0021\n",
      "Train Epoch: 24\t[20000/88956 (22%)]\tTotal Loss: 41.3655\tAvg Loss: 0.0021\n",
      "Train Epoch: 24\t[25000/88956 (28%)]\tTotal Loss: 52.4044\tAvg Loss: 0.0021\n",
      "Train Epoch: 24\t[30000/88956 (34%)]\tTotal Loss: 63.5525\tAvg Loss: 0.0021\n",
      "Train Epoch: 24\t[35000/88956 (39%)]\tTotal Loss: 74.2871\tAvg Loss: 0.0021\n",
      "Train Epoch: 24\t[40000/88956 (45%)]\tTotal Loss: 84.7980\tAvg Loss: 0.0021\n",
      "Train Epoch: 24\t[45000/88956 (51%)]\tTotal Loss: 95.2047\tAvg Loss: 0.0021\n",
      "Train Epoch: 24\t[50000/88956 (56%)]\tTotal Loss: 105.1986\tAvg Loss: 0.0021\n",
      "Train Epoch: 24\t[55000/88956 (62%)]\tTotal Loss: 115.4858\tAvg Loss: 0.0021\n",
      "Train Epoch: 24\t[60000/88956 (67%)]\tTotal Loss: 126.2954\tAvg Loss: 0.0021\n",
      "Train Epoch: 24\t[65000/88956 (73%)]\tTotal Loss: 137.2752\tAvg Loss: 0.0021\n",
      "Train Epoch: 24\t[70000/88956 (79%)]\tTotal Loss: 148.0806\tAvg Loss: 0.0021\n",
      "Train Epoch: 24\t[75000/88956 (84%)]\tTotal Loss: 158.5345\tAvg Loss: 0.0021\n",
      "Train Epoch: 24\t[80000/88956 (90%)]\tTotal Loss: 168.7685\tAvg Loss: 0.0021\n",
      "Train Epoch: 24\t[85000/88956 (96%)]\tTotal Loss: 179.1190\tAvg Loss: 0.0021\n",
      "====> Epoch: 24\tTotal Loss: 187.3998\t Avg Loss: 0.0021\t Fx Loss: 169.1378\t Set Loss: 18.2620\n",
      "\t\tCorrect: 30078/88956\tFx Correct: 78324/88956\tSet Correct: 32595/88956\n",
      "\t\tPercentage Correct: 33.81\tPercentage Fx Correct: 88.05\tPercentage Set Correct: 36.64\n",
      "====> Val Loss: 22.3605\t Avg Loss: 0.0023\t Fx Loss: 20.0189\t Set Loss: 2.3417\n",
      "\t\tCorrect: 3109/9885\tFx Correct: 8640/9885\tSet Correct: 3366/9885\n",
      "\t\tPercentage Correct: 31.45\tPercentage Fx Correct: 87.41\tPercentage Set Correct: 34.05\n",
      "====> Test Loss: 55.7964\t Avg Loss: 0.0023\t Fx Loss: 49.9921\t Set Loss: 5.8044\n",
      "\t\tCorrect: 7691/24711\tFx Correct: 21558/24711\tSet Correct: 8329/24711\n",
      "\t\tPercentage Correct: 31.12\tPercentage Fx Correct: 87.24\tPercentage Set Correct: 33.71\n",
      "Train Epoch: 25\t[5000/88956 (6%)]\tTotal Loss: 10.7448\tAvg Loss: 0.0021\n",
      "Train Epoch: 25\t[10000/88956 (11%)]\tTotal Loss: 20.2844\tAvg Loss: 0.0020\n",
      "Train Epoch: 25\t[15000/88956 (17%)]\tTotal Loss: 30.5145\tAvg Loss: 0.0020\n",
      "Train Epoch: 25\t[20000/88956 (22%)]\tTotal Loss: 40.4707\tAvg Loss: 0.0020\n",
      "Train Epoch: 25\t[25000/88956 (28%)]\tTotal Loss: 51.2946\tAvg Loss: 0.0021\n",
      "Train Epoch: 25\t[30000/88956 (34%)]\tTotal Loss: 61.4552\tAvg Loss: 0.0020\n",
      "Train Epoch: 25\t[35000/88956 (39%)]\tTotal Loss: 72.2563\tAvg Loss: 0.0021\n",
      "Train Epoch: 25\t[40000/88956 (45%)]\tTotal Loss: 83.3094\tAvg Loss: 0.0021\n",
      "Train Epoch: 25\t[45000/88956 (51%)]\tTotal Loss: 93.5450\tAvg Loss: 0.0021\n",
      "Train Epoch: 25\t[50000/88956 (56%)]\tTotal Loss: 104.3962\tAvg Loss: 0.0021\n",
      "Train Epoch: 25\t[55000/88956 (62%)]\tTotal Loss: 115.0304\tAvg Loss: 0.0021\n",
      "Train Epoch: 25\t[60000/88956 (67%)]\tTotal Loss: 124.9843\tAvg Loss: 0.0021\n",
      "Train Epoch: 25\t[65000/88956 (73%)]\tTotal Loss: 135.7225\tAvg Loss: 0.0021\n",
      "Train Epoch: 25\t[70000/88956 (79%)]\tTotal Loss: 146.7439\tAvg Loss: 0.0021\n",
      "Train Epoch: 25\t[75000/88956 (84%)]\tTotal Loss: 158.0933\tAvg Loss: 0.0021\n",
      "Train Epoch: 25\t[80000/88956 (90%)]\tTotal Loss: 168.8516\tAvg Loss: 0.0021\n",
      "Train Epoch: 25\t[85000/88956 (96%)]\tTotal Loss: 179.2958\tAvg Loss: 0.0021\n",
      "====> Epoch: 25\tTotal Loss: 187.4698\t Avg Loss: 0.0021\t Fx Loss: 169.2210\t Set Loss: 18.2488\n",
      "\t\tCorrect: 30033/88956\tFx Correct: 78190/88956\tSet Correct: 32622/88956\n",
      "\t\tPercentage Correct: 33.76\tPercentage Fx Correct: 87.90\tPercentage Set Correct: 36.67\n",
      "====> Val Loss: 21.1307\t Avg Loss: 0.0021\t Fx Loss: 19.0757\t Set Loss: 2.0550\n",
      "\t\tCorrect: 3378/9885\tFx Correct: 8669/9885\tSet Correct: 3655/9885\n",
      "\t\tPercentage Correct: 34.17\tPercentage Fx Correct: 87.70\tPercentage Set Correct: 36.98\n",
      "====> Test Loss: 53.6249\t Avg Loss: 0.0022\t Fx Loss: 48.4730\t Set Loss: 5.1519\n",
      "\t\tCorrect: 8460/24711\tFx Correct: 21572/24711\tSet Correct: 9284/24711\n",
      "\t\tPercentage Correct: 34.24\tPercentage Fx Correct: 87.30\tPercentage Set Correct: 37.57\n",
      "\n",
      "=== saved best model ===\n",
      "\n",
      "Train Epoch: 26\t[5000/88956 (6%)]\tTotal Loss: 9.8441\tAvg Loss: 0.0020\n",
      "Train Epoch: 26\t[10000/88956 (11%)]\tTotal Loss: 20.3131\tAvg Loss: 0.0020\n",
      "Train Epoch: 26\t[15000/88956 (17%)]\tTotal Loss: 30.5193\tAvg Loss: 0.0020\n",
      "Train Epoch: 26\t[20000/88956 (22%)]\tTotal Loss: 40.6831\tAvg Loss: 0.0020\n",
      "Train Epoch: 26\t[25000/88956 (28%)]\tTotal Loss: 50.1154\tAvg Loss: 0.0020\n",
      "Train Epoch: 26\t[30000/88956 (34%)]\tTotal Loss: 60.5773\tAvg Loss: 0.0020\n",
      "Train Epoch: 26\t[35000/88956 (39%)]\tTotal Loss: 70.2206\tAvg Loss: 0.0020\n",
      "Train Epoch: 26\t[40000/88956 (45%)]\tTotal Loss: 80.9123\tAvg Loss: 0.0020\n",
      "Train Epoch: 26\t[45000/88956 (51%)]\tTotal Loss: 91.4448\tAvg Loss: 0.0020\n",
      "Train Epoch: 26\t[50000/88956 (56%)]\tTotal Loss: 101.9861\tAvg Loss: 0.0020\n",
      "Train Epoch: 26\t[55000/88956 (62%)]\tTotal Loss: 114.0515\tAvg Loss: 0.0021\n",
      "Train Epoch: 26\t[60000/88956 (67%)]\tTotal Loss: 124.6818\tAvg Loss: 0.0021\n",
      "Train Epoch: 26\t[65000/88956 (73%)]\tTotal Loss: 134.5719\tAvg Loss: 0.0021\n",
      "Train Epoch: 26\t[70000/88956 (79%)]\tTotal Loss: 144.8360\tAvg Loss: 0.0021\n",
      "Train Epoch: 26\t[75000/88956 (84%)]\tTotal Loss: 154.9219\tAvg Loss: 0.0021\n",
      "Train Epoch: 26\t[80000/88956 (90%)]\tTotal Loss: 165.4178\tAvg Loss: 0.0021\n",
      "Train Epoch: 26\t[85000/88956 (96%)]\tTotal Loss: 175.7008\tAvg Loss: 0.0021\n",
      "====> Epoch: 26\tTotal Loss: 183.3585\t Avg Loss: 0.0021\t Fx Loss: 165.4323\t Set Loss: 17.9262\n",
      "\t\tCorrect: 30289/88956\tFx Correct: 78278/88956\tSet Correct: 32879/88956\n",
      "\t\tPercentage Correct: 34.05\tPercentage Fx Correct: 88.00\tPercentage Set Correct: 36.96\n",
      "====> Val Loss: 22.2619\t Avg Loss: 0.0023\t Fx Loss: 20.0391\t Set Loss: 2.2228\n",
      "\t\tCorrect: 3418/9885\tFx Correct: 8627/9885\tSet Correct: 3724/9885\n",
      "\t\tPercentage Correct: 34.58\tPercentage Fx Correct: 87.27\tPercentage Set Correct: 37.67\n",
      "====> Test Loss: 55.9288\t Avg Loss: 0.0023\t Fx Loss: 50.2462\t Set Loss: 5.6827\n",
      "\t\tCorrect: 8529/24711\tFx Correct: 21487/24711\tSet Correct: 9315/24711\n",
      "\t\tPercentage Correct: 34.51\tPercentage Fx Correct: 86.95\tPercentage Set Correct: 37.70\n",
      "\n",
      "=== saved best model ===\n",
      "\n",
      "Train Epoch: 27\t[5000/88956 (6%)]\tTotal Loss: 10.3592\tAvg Loss: 0.0021\n",
      "Train Epoch: 27\t[10000/88956 (11%)]\tTotal Loss: 20.9351\tAvg Loss: 0.0021\n",
      "Train Epoch: 27\t[15000/88956 (17%)]\tTotal Loss: 31.3905\tAvg Loss: 0.0021\n",
      "Train Epoch: 27\t[20000/88956 (22%)]\tTotal Loss: 42.4517\tAvg Loss: 0.0021\n",
      "Train Epoch: 27\t[25000/88956 (28%)]\tTotal Loss: 53.3961\tAvg Loss: 0.0021\n",
      "Train Epoch: 27\t[30000/88956 (34%)]\tTotal Loss: 63.4461\tAvg Loss: 0.0021\n",
      "Train Epoch: 27\t[35000/88956 (39%)]\tTotal Loss: 73.8719\tAvg Loss: 0.0021\n",
      "Train Epoch: 27\t[40000/88956 (45%)]\tTotal Loss: 83.9548\tAvg Loss: 0.0021\n",
      "Train Epoch: 27\t[45000/88956 (51%)]\tTotal Loss: 93.3389\tAvg Loss: 0.0021\n",
      "Train Epoch: 27\t[50000/88956 (56%)]\tTotal Loss: 103.6769\tAvg Loss: 0.0021\n",
      "Train Epoch: 27\t[55000/88956 (62%)]\tTotal Loss: 113.4968\tAvg Loss: 0.0021\n",
      "Train Epoch: 27\t[60000/88956 (67%)]\tTotal Loss: 123.6118\tAvg Loss: 0.0021\n",
      "Train Epoch: 27\t[65000/88956 (73%)]\tTotal Loss: 133.9202\tAvg Loss: 0.0021\n",
      "Train Epoch: 27\t[70000/88956 (79%)]\tTotal Loss: 143.6772\tAvg Loss: 0.0021\n",
      "Train Epoch: 27\t[75000/88956 (84%)]\tTotal Loss: 154.8123\tAvg Loss: 0.0021\n",
      "Train Epoch: 27\t[80000/88956 (90%)]\tTotal Loss: 165.6244\tAvg Loss: 0.0021\n",
      "Train Epoch: 27\t[85000/88956 (96%)]\tTotal Loss: 175.6772\tAvg Loss: 0.0021\n",
      "====> Epoch: 27\tTotal Loss: 183.8666\t Avg Loss: 0.0021\t Fx Loss: 166.0476\t Set Loss: 17.8190\n",
      "\t\tCorrect: 30998/88956\tFx Correct: 78329/88956\tSet Correct: 33616/88956\n",
      "\t\tPercentage Correct: 34.85\tPercentage Fx Correct: 88.05\tPercentage Set Correct: 37.79\n",
      "====> Val Loss: 22.1735\t Avg Loss: 0.0022\t Fx Loss: 20.0496\t Set Loss: 2.1239\n",
      "\t\tCorrect: 3324/9885\tFx Correct: 8600/9885\tSet Correct: 3590/9885\n",
      "\t\tPercentage Correct: 33.63\tPercentage Fx Correct: 87.00\tPercentage Set Correct: 36.32\n",
      "====> Test Loss: 55.5494\t Avg Loss: 0.0022\t Fx Loss: 50.2519\t Set Loss: 5.2975\n",
      "\t\tCorrect: 8429/24711\tFx Correct: 21716/24711\tSet Correct: 9093/24711\n",
      "\t\tPercentage Correct: 34.11\tPercentage Fx Correct: 87.88\tPercentage Set Correct: 36.80\n",
      "Train Epoch: 28\t[5000/88956 (6%)]\tTotal Loss: 10.0756\tAvg Loss: 0.0020\n",
      "Train Epoch: 28\t[10000/88956 (11%)]\tTotal Loss: 19.9790\tAvg Loss: 0.0020\n",
      "Train Epoch: 28\t[15000/88956 (17%)]\tTotal Loss: 30.1982\tAvg Loss: 0.0020\n",
      "Train Epoch: 28\t[20000/88956 (22%)]\tTotal Loss: 39.6935\tAvg Loss: 0.0020\n",
      "Train Epoch: 28\t[25000/88956 (28%)]\tTotal Loss: 49.6811\tAvg Loss: 0.0020\n",
      "Train Epoch: 28\t[30000/88956 (34%)]\tTotal Loss: 59.7838\tAvg Loss: 0.0020\n",
      "Train Epoch: 28\t[35000/88956 (39%)]\tTotal Loss: 69.8205\tAvg Loss: 0.0020\n",
      "Train Epoch: 28\t[40000/88956 (45%)]\tTotal Loss: 80.6175\tAvg Loss: 0.0020\n",
      "Train Epoch: 28\t[45000/88956 (51%)]\tTotal Loss: 90.7795\tAvg Loss: 0.0020\n",
      "Train Epoch: 28\t[50000/88956 (56%)]\tTotal Loss: 100.9760\tAvg Loss: 0.0020\n",
      "Train Epoch: 28\t[55000/88956 (62%)]\tTotal Loss: 110.8323\tAvg Loss: 0.0020\n",
      "Train Epoch: 28\t[60000/88956 (67%)]\tTotal Loss: 121.5326\tAvg Loss: 0.0020\n",
      "Train Epoch: 28\t[65000/88956 (73%)]\tTotal Loss: 131.7826\tAvg Loss: 0.0020\n",
      "Train Epoch: 28\t[70000/88956 (79%)]\tTotal Loss: 141.9234\tAvg Loss: 0.0020\n",
      "Train Epoch: 28\t[75000/88956 (84%)]\tTotal Loss: 152.8844\tAvg Loss: 0.0020\n",
      "Train Epoch: 28\t[80000/88956 (90%)]\tTotal Loss: 162.6233\tAvg Loss: 0.0020\n",
      "Train Epoch: 28\t[85000/88956 (96%)]\tTotal Loss: 173.4067\tAvg Loss: 0.0020\n",
      "====> Epoch: 28\tTotal Loss: 181.7121\t Avg Loss: 0.0020\t Fx Loss: 164.5115\t Set Loss: 17.2005\n",
      "\t\tCorrect: 31327/88956\tFx Correct: 78311/88956\tSet Correct: 33971/88956\n",
      "\t\tPercentage Correct: 35.22\tPercentage Fx Correct: 88.03\tPercentage Set Correct: 38.19\n",
      "====> Val Loss: 23.1637\t Avg Loss: 0.0023\t Fx Loss: 20.9675\t Set Loss: 2.1962\n",
      "\t\tCorrect: 3235/9885\tFx Correct: 8588/9885\tSet Correct: 3488/9885\n",
      "\t\tPercentage Correct: 32.73\tPercentage Fx Correct: 86.88\tPercentage Set Correct: 35.29\n",
      "====> Test Loss: 55.3407\t Avg Loss: 0.0022\t Fx Loss: 49.9641\t Set Loss: 5.3766\n",
      "\t\tCorrect: 8147/24711\tFx Correct: 21726/24711\tSet Correct: 8764/24711\n",
      "\t\tPercentage Correct: 32.97\tPercentage Fx Correct: 87.92\tPercentage Set Correct: 35.47\n",
      "Train Epoch: 29\t[5000/88956 (6%)]\tTotal Loss: 11.4854\tAvg Loss: 0.0023\n",
      "Train Epoch: 29\t[10000/88956 (11%)]\tTotal Loss: 21.6718\tAvg Loss: 0.0022\n",
      "Train Epoch: 29\t[15000/88956 (17%)]\tTotal Loss: 31.4762\tAvg Loss: 0.0021\n",
      "Train Epoch: 29\t[20000/88956 (22%)]\tTotal Loss: 41.2370\tAvg Loss: 0.0021\n",
      "Train Epoch: 29\t[25000/88956 (28%)]\tTotal Loss: 51.0431\tAvg Loss: 0.0020\n",
      "Train Epoch: 29\t[30000/88956 (34%)]\tTotal Loss: 61.3073\tAvg Loss: 0.0020\n",
      "Train Epoch: 29\t[35000/88956 (39%)]\tTotal Loss: 70.8195\tAvg Loss: 0.0020\n",
      "Train Epoch: 29\t[40000/88956 (45%)]\tTotal Loss: 80.3169\tAvg Loss: 0.0020\n",
      "Train Epoch: 29\t[45000/88956 (51%)]\tTotal Loss: 89.9954\tAvg Loss: 0.0020\n",
      "Train Epoch: 29\t[50000/88956 (56%)]\tTotal Loss: 99.4955\tAvg Loss: 0.0020\n",
      "Train Epoch: 29\t[55000/88956 (62%)]\tTotal Loss: 109.8013\tAvg Loss: 0.0020\n",
      "Train Epoch: 29\t[60000/88956 (67%)]\tTotal Loss: 120.1159\tAvg Loss: 0.0020\n",
      "Train Epoch: 29\t[65000/88956 (73%)]\tTotal Loss: 130.9231\tAvg Loss: 0.0020\n",
      "Train Epoch: 29\t[70000/88956 (79%)]\tTotal Loss: 141.5506\tAvg Loss: 0.0020\n",
      "Train Epoch: 29\t[75000/88956 (84%)]\tTotal Loss: 151.6186\tAvg Loss: 0.0020\n",
      "Train Epoch: 29\t[80000/88956 (90%)]\tTotal Loss: 162.1649\tAvg Loss: 0.0020\n",
      "Train Epoch: 29\t[85000/88956 (96%)]\tTotal Loss: 172.0128\tAvg Loss: 0.0020\n",
      "====> Epoch: 29\tTotal Loss: 180.1582\t Avg Loss: 0.0020\t Fx Loss: 163.2346\t Set Loss: 16.9236\n",
      "\t\tCorrect: 31529/88956\tFx Correct: 78544/88956\tSet Correct: 34150/88956\n",
      "\t\tPercentage Correct: 35.44\tPercentage Fx Correct: 88.30\tPercentage Set Correct: 38.39\n",
      "====> Val Loss: 21.8946\t Avg Loss: 0.0022\t Fx Loss: 19.9102\t Set Loss: 1.9845\n",
      "\t\tCorrect: 3503/9885\tFx Correct: 8654/9885\tSet Correct: 3794/9885\n",
      "\t\tPercentage Correct: 35.44\tPercentage Fx Correct: 87.55\tPercentage Set Correct: 38.38\n",
      "====> Test Loss: 54.1120\t Avg Loss: 0.0022\t Fx Loss: 49.1587\t Set Loss: 4.9533\n",
      "\t\tCorrect: 8708/24711\tFx Correct: 21668/24711\tSet Correct: 9428/24711\n",
      "\t\tPercentage Correct: 35.24\tPercentage Fx Correct: 87.69\tPercentage Set Correct: 38.15\n",
      "\n",
      "=== saved best model ===\n",
      "\n",
      "Train Epoch: 30\t[5000/88956 (6%)]\tTotal Loss: 9.9520\tAvg Loss: 0.0020\n",
      "Train Epoch: 30\t[10000/88956 (11%)]\tTotal Loss: 19.7998\tAvg Loss: 0.0020\n",
      "Train Epoch: 30\t[15000/88956 (17%)]\tTotal Loss: 29.2568\tAvg Loss: 0.0020\n",
      "Train Epoch: 30\t[20000/88956 (22%)]\tTotal Loss: 39.1951\tAvg Loss: 0.0020\n",
      "Train Epoch: 30\t[25000/88956 (28%)]\tTotal Loss: 49.0800\tAvg Loss: 0.0020\n",
      "Train Epoch: 30\t[30000/88956 (34%)]\tTotal Loss: 58.6440\tAvg Loss: 0.0020\n",
      "Train Epoch: 30\t[35000/88956 (39%)]\tTotal Loss: 68.7087\tAvg Loss: 0.0020\n",
      "Train Epoch: 30\t[40000/88956 (45%)]\tTotal Loss: 78.5816\tAvg Loss: 0.0020\n",
      "Train Epoch: 30\t[45000/88956 (51%)]\tTotal Loss: 89.0133\tAvg Loss: 0.0020\n",
      "Train Epoch: 30\t[50000/88956 (56%)]\tTotal Loss: 99.1841\tAvg Loss: 0.0020\n",
      "Train Epoch: 30\t[55000/88956 (62%)]\tTotal Loss: 110.0858\tAvg Loss: 0.0020\n",
      "Train Epoch: 30\t[60000/88956 (67%)]\tTotal Loss: 120.4092\tAvg Loss: 0.0020\n",
      "Train Epoch: 30\t[65000/88956 (73%)]\tTotal Loss: 130.1564\tAvg Loss: 0.0020\n",
      "Train Epoch: 30\t[70000/88956 (79%)]\tTotal Loss: 139.3973\tAvg Loss: 0.0020\n",
      "Train Epoch: 30\t[75000/88956 (84%)]\tTotal Loss: 149.3151\tAvg Loss: 0.0020\n",
      "Train Epoch: 30\t[80000/88956 (90%)]\tTotal Loss: 160.2414\tAvg Loss: 0.0020\n",
      "Train Epoch: 30\t[85000/88956 (96%)]\tTotal Loss: 170.4134\tAvg Loss: 0.0020\n",
      "====> Epoch: 30\tTotal Loss: 177.7703\t Avg Loss: 0.0020\t Fx Loss: 161.4576\t Set Loss: 16.3127\n",
      "\t\tCorrect: 31978/88956\tFx Correct: 78594/88956\tSet Correct: 34653/88956\n",
      "\t\tPercentage Correct: 35.95\tPercentage Fx Correct: 88.35\tPercentage Set Correct: 38.96\n",
      "====> Val Loss: 21.1323\t Avg Loss: 0.0021\t Fx Loss: 19.2114\t Set Loss: 1.9209\n",
      "\t\tCorrect: 3584/9885\tFx Correct: 8655/9885\tSet Correct: 3878/9885\n",
      "\t\tPercentage Correct: 36.26\tPercentage Fx Correct: 87.56\tPercentage Set Correct: 39.23\n",
      "====> Test Loss: 52.5293\t Avg Loss: 0.0021\t Fx Loss: 47.6038\t Set Loss: 4.9255\n",
      "\t\tCorrect: 9014/24711\tFx Correct: 21799/24711\tSet Correct: 9715/24711\n",
      "\t\tPercentage Correct: 36.48\tPercentage Fx Correct: 88.22\tPercentage Set Correct: 39.31\n",
      "\n",
      "=== saved best model ===\n",
      "\n",
      "Train Epoch: 31\t[5000/88956 (6%)]\tTotal Loss: 9.5508\tAvg Loss: 0.0019\n",
      "Train Epoch: 31\t[10000/88956 (11%)]\tTotal Loss: 18.8879\tAvg Loss: 0.0019\n",
      "Train Epoch: 31\t[15000/88956 (17%)]\tTotal Loss: 28.7834\tAvg Loss: 0.0019\n",
      "Train Epoch: 31\t[20000/88956 (22%)]\tTotal Loss: 38.2321\tAvg Loss: 0.0019\n",
      "Train Epoch: 31\t[25000/88956 (28%)]\tTotal Loss: 47.9444\tAvg Loss: 0.0019\n",
      "Train Epoch: 31\t[30000/88956 (34%)]\tTotal Loss: 57.9763\tAvg Loss: 0.0019\n",
      "Train Epoch: 31\t[35000/88956 (39%)]\tTotal Loss: 68.4717\tAvg Loss: 0.0020\n",
      "Train Epoch: 31\t[40000/88956 (45%)]\tTotal Loss: 78.0690\tAvg Loss: 0.0020\n",
      "Train Epoch: 31\t[45000/88956 (51%)]\tTotal Loss: 88.1702\tAvg Loss: 0.0020\n",
      "Train Epoch: 31\t[50000/88956 (56%)]\tTotal Loss: 98.0364\tAvg Loss: 0.0020\n",
      "Train Epoch: 31\t[55000/88956 (62%)]\tTotal Loss: 107.5584\tAvg Loss: 0.0020\n",
      "Train Epoch: 31\t[60000/88956 (67%)]\tTotal Loss: 117.7185\tAvg Loss: 0.0020\n",
      "Train Epoch: 31\t[65000/88956 (73%)]\tTotal Loss: 128.0832\tAvg Loss: 0.0020\n",
      "Train Epoch: 31\t[70000/88956 (79%)]\tTotal Loss: 137.7727\tAvg Loss: 0.0020\n",
      "Train Epoch: 31\t[75000/88956 (84%)]\tTotal Loss: 147.0596\tAvg Loss: 0.0020\n",
      "Train Epoch: 31\t[80000/88956 (90%)]\tTotal Loss: 156.9566\tAvg Loss: 0.0020\n",
      "Train Epoch: 31\t[85000/88956 (96%)]\tTotal Loss: 167.3147\tAvg Loss: 0.0020\n",
      "====> Epoch: 31\tTotal Loss: 174.5269\t Avg Loss: 0.0020\t Fx Loss: 158.6069\t Set Loss: 15.9200\n",
      "\t\tCorrect: 32407/88956\tFx Correct: 78688/88956\tSet Correct: 35112/88956\n",
      "\t\tPercentage Correct: 36.43\tPercentage Fx Correct: 88.46\tPercentage Set Correct: 39.47\n",
      "====> Val Loss: 23.5148\t Avg Loss: 0.0024\t Fx Loss: 21.4784\t Set Loss: 2.0364\n",
      "\t\tCorrect: 3688/9885\tFx Correct: 8627/9885\tSet Correct: 3969/9885\n",
      "\t\tPercentage Correct: 37.31\tPercentage Fx Correct: 87.27\tPercentage Set Correct: 40.15\n",
      "====> Test Loss: 57.5692\t Avg Loss: 0.0023\t Fx Loss: 52.5191\t Set Loss: 5.0501\n",
      "\t\tCorrect: 9035/24711\tFx Correct: 21517/24711\tSet Correct: 9850/24711\n",
      "\t\tPercentage Correct: 36.56\tPercentage Fx Correct: 87.07\tPercentage Set Correct: 39.86\n",
      "\n",
      "=== saved best model ===\n",
      "\n",
      "Train Epoch: 32\t[5000/88956 (6%)]\tTotal Loss: 10.1861\tAvg Loss: 0.0020\n",
      "Train Epoch: 32\t[10000/88956 (11%)]\tTotal Loss: 19.3642\tAvg Loss: 0.0019\n",
      "Train Epoch: 32\t[15000/88956 (17%)]\tTotal Loss: 29.0776\tAvg Loss: 0.0019\n",
      "Train Epoch: 32\t[20000/88956 (22%)]\tTotal Loss: 39.0621\tAvg Loss: 0.0020\n",
      "Train Epoch: 32\t[25000/88956 (28%)]\tTotal Loss: 49.8009\tAvg Loss: 0.0020\n",
      "Train Epoch: 32\t[30000/88956 (34%)]\tTotal Loss: 58.7809\tAvg Loss: 0.0020\n",
      "Train Epoch: 32\t[35000/88956 (39%)]\tTotal Loss: 68.2126\tAvg Loss: 0.0019\n",
      "Train Epoch: 32\t[40000/88956 (45%)]\tTotal Loss: 77.2622\tAvg Loss: 0.0019\n",
      "Train Epoch: 32\t[45000/88956 (51%)]\tTotal Loss: 86.7992\tAvg Loss: 0.0019\n",
      "Train Epoch: 32\t[50000/88956 (56%)]\tTotal Loss: 96.8772\tAvg Loss: 0.0019\n",
      "Train Epoch: 32\t[55000/88956 (62%)]\tTotal Loss: 106.6349\tAvg Loss: 0.0019\n",
      "Train Epoch: 32\t[60000/88956 (67%)]\tTotal Loss: 116.1854\tAvg Loss: 0.0019\n",
      "Train Epoch: 32\t[65000/88956 (73%)]\tTotal Loss: 125.9585\tAvg Loss: 0.0019\n",
      "Train Epoch: 32\t[70000/88956 (79%)]\tTotal Loss: 135.8886\tAvg Loss: 0.0019\n",
      "Train Epoch: 32\t[75000/88956 (84%)]\tTotal Loss: 145.6839\tAvg Loss: 0.0019\n",
      "Train Epoch: 32\t[80000/88956 (90%)]\tTotal Loss: 156.1336\tAvg Loss: 0.0020\n",
      "Train Epoch: 32\t[85000/88956 (96%)]\tTotal Loss: 166.7058\tAvg Loss: 0.0020\n",
      "====> Epoch: 32\tTotal Loss: 174.5564\t Avg Loss: 0.0020\t Fx Loss: 158.7362\t Set Loss: 15.8202\n",
      "\t\tCorrect: 32923/88956\tFx Correct: 78557/88956\tSet Correct: 35713/88956\n",
      "\t\tPercentage Correct: 37.01\tPercentage Fx Correct: 88.31\tPercentage Set Correct: 40.15\n",
      "====> Val Loss: 24.4846\t Avg Loss: 0.0025\t Fx Loss: 22.3399\t Set Loss: 2.1448\n",
      "\t\tCorrect: 3482/9885\tFx Correct: 8624/9885\tSet Correct: 3784/9885\n",
      "\t\tPercentage Correct: 35.23\tPercentage Fx Correct: 87.24\tPercentage Set Correct: 38.28\n",
      "====> Test Loss: 61.1049\t Avg Loss: 0.0025\t Fx Loss: 55.6709\t Set Loss: 5.4340\n",
      "\t\tCorrect: 8730/24711\tFx Correct: 21407/24711\tSet Correct: 9518/24711\n",
      "\t\tPercentage Correct: 35.33\tPercentage Fx Correct: 86.63\tPercentage Set Correct: 38.52\n",
      "Train Epoch: 33\t[5000/88956 (6%)]\tTotal Loss: 10.5143\tAvg Loss: 0.0021\n",
      "Train Epoch: 33\t[10000/88956 (11%)]\tTotal Loss: 21.1071\tAvg Loss: 0.0021\n",
      "Train Epoch: 33\t[15000/88956 (17%)]\tTotal Loss: 30.8326\tAvg Loss: 0.0021\n",
      "Train Epoch: 33\t[20000/88956 (22%)]\tTotal Loss: 40.4152\tAvg Loss: 0.0020\n",
      "Train Epoch: 33\t[25000/88956 (28%)]\tTotal Loss: 51.0551\tAvg Loss: 0.0020\n",
      "Train Epoch: 33\t[30000/88956 (34%)]\tTotal Loss: 60.8183\tAvg Loss: 0.0020\n",
      "Train Epoch: 33\t[35000/88956 (39%)]\tTotal Loss: 70.5463\tAvg Loss: 0.0020\n",
      "Train Epoch: 33\t[40000/88956 (45%)]\tTotal Loss: 79.4795\tAvg Loss: 0.0020\n",
      "Train Epoch: 33\t[45000/88956 (51%)]\tTotal Loss: 89.0578\tAvg Loss: 0.0020\n",
      "Train Epoch: 33\t[50000/88956 (56%)]\tTotal Loss: 98.6009\tAvg Loss: 0.0020\n",
      "Train Epoch: 33\t[55000/88956 (62%)]\tTotal Loss: 108.3110\tAvg Loss: 0.0020\n",
      "Train Epoch: 33\t[60000/88956 (67%)]\tTotal Loss: 118.1087\tAvg Loss: 0.0020\n",
      "Train Epoch: 33\t[65000/88956 (73%)]\tTotal Loss: 127.0044\tAvg Loss: 0.0020\n",
      "Train Epoch: 33\t[70000/88956 (79%)]\tTotal Loss: 136.2298\tAvg Loss: 0.0019\n",
      "Train Epoch: 33\t[75000/88956 (84%)]\tTotal Loss: 146.1048\tAvg Loss: 0.0019\n",
      "Train Epoch: 33\t[80000/88956 (90%)]\tTotal Loss: 156.2236\tAvg Loss: 0.0020\n",
      "Train Epoch: 33\t[85000/88956 (96%)]\tTotal Loss: 165.7756\tAvg Loss: 0.0020\n",
      "====> Epoch: 33\tTotal Loss: 173.1867\t Avg Loss: 0.0019\t Fx Loss: 157.7744\t Set Loss: 15.4123\n",
      "\t\tCorrect: 33247/88956\tFx Correct: 78810/88956\tSet Correct: 35923/88956\n",
      "\t\tPercentage Correct: 37.37\tPercentage Fx Correct: 88.59\tPercentage Set Correct: 40.38\n",
      "====> Val Loss: 20.9283\t Avg Loss: 0.0021\t Fx Loss: 19.0941\t Set Loss: 1.8342\n",
      "\t\tCorrect: 3748/9885\tFx Correct: 8661/9885\tSet Correct: 4044/9885\n",
      "\t\tPercentage Correct: 37.92\tPercentage Fx Correct: 87.62\tPercentage Set Correct: 40.91\n",
      "====> Test Loss: 51.7497\t Avg Loss: 0.0021\t Fx Loss: 47.2849\t Set Loss: 4.4648\n",
      "\t\tCorrect: 9551/24711\tFx Correct: 21861/24711\tSet Correct: 10288/24711\n",
      "\t\tPercentage Correct: 38.65\tPercentage Fx Correct: 88.47\tPercentage Set Correct: 41.63\n",
      "\n",
      "=== saved best model ===\n",
      "\n",
      "Train Epoch: 34\t[5000/88956 (6%)]\tTotal Loss: 9.5016\tAvg Loss: 0.0019\n",
      "Train Epoch: 34\t[10000/88956 (11%)]\tTotal Loss: 18.9458\tAvg Loss: 0.0019\n",
      "Train Epoch: 34\t[15000/88956 (17%)]\tTotal Loss: 28.2768\tAvg Loss: 0.0019\n",
      "Train Epoch: 34\t[20000/88956 (22%)]\tTotal Loss: 37.5706\tAvg Loss: 0.0019\n",
      "Train Epoch: 34\t[25000/88956 (28%)]\tTotal Loss: 47.1008\tAvg Loss: 0.0019\n",
      "Train Epoch: 34\t[30000/88956 (34%)]\tTotal Loss: 57.2222\tAvg Loss: 0.0019\n",
      "Train Epoch: 34\t[35000/88956 (39%)]\tTotal Loss: 67.3117\tAvg Loss: 0.0019\n",
      "Train Epoch: 34\t[40000/88956 (45%)]\tTotal Loss: 76.3744\tAvg Loss: 0.0019\n",
      "Train Epoch: 34\t[45000/88956 (51%)]\tTotal Loss: 85.7063\tAvg Loss: 0.0019\n",
      "Train Epoch: 34\t[50000/88956 (56%)]\tTotal Loss: 95.2640\tAvg Loss: 0.0019\n",
      "Train Epoch: 34\t[55000/88956 (62%)]\tTotal Loss: 104.2118\tAvg Loss: 0.0019\n",
      "Train Epoch: 34\t[60000/88956 (67%)]\tTotal Loss: 113.6371\tAvg Loss: 0.0019\n",
      "Train Epoch: 34\t[65000/88956 (73%)]\tTotal Loss: 123.1405\tAvg Loss: 0.0019\n",
      "Train Epoch: 34\t[70000/88956 (79%)]\tTotal Loss: 133.1908\tAvg Loss: 0.0019\n",
      "Train Epoch: 34\t[75000/88956 (84%)]\tTotal Loss: 143.0575\tAvg Loss: 0.0019\n",
      "Train Epoch: 34\t[80000/88956 (90%)]\tTotal Loss: 152.3024\tAvg Loss: 0.0019\n",
      "Train Epoch: 34\t[85000/88956 (96%)]\tTotal Loss: 161.9754\tAvg Loss: 0.0019\n",
      "====> Epoch: 34\tTotal Loss: 169.7830\t Avg Loss: 0.0019\t Fx Loss: 155.1748\t Set Loss: 14.6082\n",
      "\t\tCorrect: 34181/88956\tFx Correct: 78865/88956\tSet Correct: 36988/88956\n",
      "\t\tPercentage Correct: 38.42\tPercentage Fx Correct: 88.66\tPercentage Set Correct: 41.58\n",
      "====> Val Loss: 21.6021\t Avg Loss: 0.0022\t Fx Loss: 19.6649\t Set Loss: 1.9372\n",
      "\t\tCorrect: 3720/9885\tFx Correct: 8646/9885\tSet Correct: 4061/9885\n",
      "\t\tPercentage Correct: 37.63\tPercentage Fx Correct: 87.47\tPercentage Set Correct: 41.08\n",
      "====> Test Loss: 54.0197\t Avg Loss: 0.0022\t Fx Loss: 49.1851\t Set Loss: 4.8346\n",
      "\t\tCorrect: 9527/24711\tFx Correct: 21824/24711\tSet Correct: 10280/24711\n",
      "\t\tPercentage Correct: 38.55\tPercentage Fx Correct: 88.32\tPercentage Set Correct: 41.60\n",
      "Train Epoch: 35\t[5000/88956 (6%)]\tTotal Loss: 10.2366\tAvg Loss: 0.0020\n",
      "Train Epoch: 35\t[10000/88956 (11%)]\tTotal Loss: 19.9589\tAvg Loss: 0.0020\n",
      "Train Epoch: 35\t[15000/88956 (17%)]\tTotal Loss: 29.0393\tAvg Loss: 0.0019\n",
      "Train Epoch: 35\t[20000/88956 (22%)]\tTotal Loss: 38.4046\tAvg Loss: 0.0019\n",
      "Train Epoch: 35\t[25000/88956 (28%)]\tTotal Loss: 47.3185\tAvg Loss: 0.0019\n",
      "Train Epoch: 35\t[30000/88956 (34%)]\tTotal Loss: 57.2638\tAvg Loss: 0.0019\n",
      "Train Epoch: 35\t[35000/88956 (39%)]\tTotal Loss: 66.8508\tAvg Loss: 0.0019\n",
      "Train Epoch: 35\t[40000/88956 (45%)]\tTotal Loss: 76.4133\tAvg Loss: 0.0019\n",
      "Train Epoch: 35\t[45000/88956 (51%)]\tTotal Loss: 85.4973\tAvg Loss: 0.0019\n",
      "Train Epoch: 35\t[50000/88956 (56%)]\tTotal Loss: 94.4525\tAvg Loss: 0.0019\n",
      "Train Epoch: 35\t[55000/88956 (62%)]\tTotal Loss: 103.6024\tAvg Loss: 0.0019\n",
      "Train Epoch: 35\t[60000/88956 (67%)]\tTotal Loss: 112.7671\tAvg Loss: 0.0019\n",
      "Train Epoch: 35\t[65000/88956 (73%)]\tTotal Loss: 122.2355\tAvg Loss: 0.0019\n",
      "Train Epoch: 35\t[70000/88956 (79%)]\tTotal Loss: 131.9004\tAvg Loss: 0.0019\n",
      "Train Epoch: 35\t[75000/88956 (84%)]\tTotal Loss: 141.8228\tAvg Loss: 0.0019\n",
      "Train Epoch: 35\t[80000/88956 (90%)]\tTotal Loss: 151.8975\tAvg Loss: 0.0019\n",
      "Train Epoch: 35\t[85000/88956 (96%)]\tTotal Loss: 160.9402\tAvg Loss: 0.0019\n",
      "====> Epoch: 35\tTotal Loss: 168.2271\t Avg Loss: 0.0019\t Fx Loss: 153.6754\t Set Loss: 14.5517\n",
      "\t\tCorrect: 34619/88956\tFx Correct: 78874/88956\tSet Correct: 37336/88956\n",
      "\t\tPercentage Correct: 38.92\tPercentage Fx Correct: 88.67\tPercentage Set Correct: 41.97\n",
      "====> Val Loss: 21.3308\t Avg Loss: 0.0022\t Fx Loss: 19.4490\t Set Loss: 1.8818\n",
      "\t\tCorrect: 3886/9885\tFx Correct: 8699/9885\tSet Correct: 4233/9885\n",
      "\t\tPercentage Correct: 39.31\tPercentage Fx Correct: 88.00\tPercentage Set Correct: 42.82\n",
      "====> Test Loss: 52.9509\t Avg Loss: 0.0021\t Fx Loss: 48.3231\t Set Loss: 4.6279\n",
      "\t\tCorrect: 9644/24711\tFx Correct: 21630/24711\tSet Correct: 10541/24711\n",
      "\t\tPercentage Correct: 39.03\tPercentage Fx Correct: 87.53\tPercentage Set Correct: 42.66\n",
      "\n",
      "=== saved best model ===\n",
      "\n",
      "Train Epoch: 36\t[5000/88956 (6%)]\tTotal Loss: 10.6351\tAvg Loss: 0.0021\n",
      "Train Epoch: 36\t[10000/88956 (11%)]\tTotal Loss: 19.6643\tAvg Loss: 0.0020\n",
      "Train Epoch: 36\t[15000/88956 (17%)]\tTotal Loss: 29.0177\tAvg Loss: 0.0019\n",
      "Train Epoch: 36\t[20000/88956 (22%)]\tTotal Loss: 38.9738\tAvg Loss: 0.0019\n",
      "Train Epoch: 36\t[25000/88956 (28%)]\tTotal Loss: 49.2544\tAvg Loss: 0.0020\n",
      "Train Epoch: 36\t[30000/88956 (34%)]\tTotal Loss: 59.3147\tAvg Loss: 0.0020\n",
      "Train Epoch: 36\t[35000/88956 (39%)]\tTotal Loss: 69.6594\tAvg Loss: 0.0020\n",
      "Train Epoch: 36\t[40000/88956 (45%)]\tTotal Loss: 79.0484\tAvg Loss: 0.0020\n",
      "Train Epoch: 36\t[45000/88956 (51%)]\tTotal Loss: 88.2002\tAvg Loss: 0.0020\n",
      "Train Epoch: 36\t[50000/88956 (56%)]\tTotal Loss: 97.4910\tAvg Loss: 0.0019\n",
      "Train Epoch: 36\t[55000/88956 (62%)]\tTotal Loss: 106.9464\tAvg Loss: 0.0019\n",
      "Train Epoch: 36\t[60000/88956 (67%)]\tTotal Loss: 116.5729\tAvg Loss: 0.0019\n",
      "Train Epoch: 36\t[65000/88956 (73%)]\tTotal Loss: 126.2504\tAvg Loss: 0.0019\n",
      "Train Epoch: 36\t[70000/88956 (79%)]\tTotal Loss: 135.6493\tAvg Loss: 0.0019\n",
      "Train Epoch: 36\t[75000/88956 (84%)]\tTotal Loss: 145.3147\tAvg Loss: 0.0019\n",
      "Train Epoch: 36\t[80000/88956 (90%)]\tTotal Loss: 155.5047\tAvg Loss: 0.0019\n",
      "Train Epoch: 36\t[85000/88956 (96%)]\tTotal Loss: 165.0764\tAvg Loss: 0.0019\n",
      "====> Epoch: 36\tTotal Loss: 172.1627\t Avg Loss: 0.0019\t Fx Loss: 156.9025\t Set Loss: 15.2603\n",
      "\t\tCorrect: 33545/88956\tFx Correct: 78789/88956\tSet Correct: 36272/88956\n",
      "\t\tPercentage Correct: 37.71\tPercentage Fx Correct: 88.57\tPercentage Set Correct: 40.78\n",
      "====> Val Loss: 21.8263\t Avg Loss: 0.0022\t Fx Loss: 19.9074\t Set Loss: 1.9189\n",
      "\t\tCorrect: 3748/9885\tFx Correct: 8641/9885\tSet Correct: 4060/9885\n",
      "\t\tPercentage Correct: 37.92\tPercentage Fx Correct: 87.42\tPercentage Set Correct: 41.07\n",
      "====> Test Loss: 53.5814\t Avg Loss: 0.0022\t Fx Loss: 48.8291\t Set Loss: 4.7523\n",
      "\t\tCorrect: 9483/24711\tFx Correct: 21770/24711\tSet Correct: 10224/24711\n",
      "\t\tPercentage Correct: 38.38\tPercentage Fx Correct: 88.10\tPercentage Set Correct: 41.37\n",
      "Train Epoch: 37\t[5000/88956 (6%)]\tTotal Loss: 8.9600\tAvg Loss: 0.0018\n",
      "Train Epoch: 37\t[10000/88956 (11%)]\tTotal Loss: 18.5419\tAvg Loss: 0.0019\n",
      "Train Epoch: 37\t[15000/88956 (17%)]\tTotal Loss: 27.6379\tAvg Loss: 0.0018\n",
      "Train Epoch: 37\t[20000/88956 (22%)]\tTotal Loss: 36.6877\tAvg Loss: 0.0018\n",
      "Train Epoch: 37\t[25000/88956 (28%)]\tTotal Loss: 46.1865\tAvg Loss: 0.0018\n",
      "Train Epoch: 37\t[30000/88956 (34%)]\tTotal Loss: 55.4235\tAvg Loss: 0.0018\n",
      "Train Epoch: 37\t[35000/88956 (39%)]\tTotal Loss: 64.9236\tAvg Loss: 0.0019\n",
      "Train Epoch: 37\t[40000/88956 (45%)]\tTotal Loss: 73.6067\tAvg Loss: 0.0018\n",
      "Train Epoch: 37\t[45000/88956 (51%)]\tTotal Loss: 82.8424\tAvg Loss: 0.0018\n",
      "Train Epoch: 37\t[50000/88956 (56%)]\tTotal Loss: 92.2972\tAvg Loss: 0.0018\n",
      "Train Epoch: 37\t[55000/88956 (62%)]\tTotal Loss: 101.3869\tAvg Loss: 0.0018\n",
      "Train Epoch: 37\t[60000/88956 (67%)]\tTotal Loss: 110.7877\tAvg Loss: 0.0018\n",
      "Train Epoch: 37\t[65000/88956 (73%)]\tTotal Loss: 119.8190\tAvg Loss: 0.0018\n",
      "Train Epoch: 37\t[70000/88956 (79%)]\tTotal Loss: 129.2333\tAvg Loss: 0.0018\n",
      "Train Epoch: 37\t[75000/88956 (84%)]\tTotal Loss: 138.8585\tAvg Loss: 0.0019\n",
      "Train Epoch: 37\t[80000/88956 (90%)]\tTotal Loss: 148.2502\tAvg Loss: 0.0019\n",
      "Train Epoch: 37\t[85000/88956 (96%)]\tTotal Loss: 157.9650\tAvg Loss: 0.0019\n",
      "====> Epoch: 37\tTotal Loss: 165.6199\t Avg Loss: 0.0019\t Fx Loss: 151.6354\t Set Loss: 13.9845\n",
      "\t\tCorrect: 34964/88956\tFx Correct: 79094/88956\tSet Correct: 37744/88956\n",
      "\t\tPercentage Correct: 39.30\tPercentage Fx Correct: 88.91\tPercentage Set Correct: 42.43\n",
      "====> Val Loss: 21.1230\t Avg Loss: 0.0021\t Fx Loss: 19.2494\t Set Loss: 1.8736\n",
      "\t\tCorrect: 3727/9885\tFx Correct: 8677/9885\tSet Correct: 4024/9885\n",
      "\t\tPercentage Correct: 37.70\tPercentage Fx Correct: 87.78\tPercentage Set Correct: 40.71\n",
      "====> Test Loss: 52.4884\t Avg Loss: 0.0021\t Fx Loss: 47.9225\t Set Loss: 4.5659\n",
      "\t\tCorrect: 9412/24711\tFx Correct: 21734/24711\tSet Correct: 10175/24711\n",
      "\t\tPercentage Correct: 38.09\tPercentage Fx Correct: 87.95\tPercentage Set Correct: 41.18\n",
      "Train Epoch: 38\t[5000/88956 (6%)]\tTotal Loss: 9.6121\tAvg Loss: 0.0019\n",
      "Train Epoch: 38\t[10000/88956 (11%)]\tTotal Loss: 19.0460\tAvg Loss: 0.0019\n",
      "Train Epoch: 38\t[15000/88956 (17%)]\tTotal Loss: 28.7470\tAvg Loss: 0.0019\n",
      "Train Epoch: 38\t[20000/88956 (22%)]\tTotal Loss: 38.6884\tAvg Loss: 0.0019\n",
      "Train Epoch: 38\t[25000/88956 (28%)]\tTotal Loss: 47.9790\tAvg Loss: 0.0019\n",
      "Train Epoch: 38\t[30000/88956 (34%)]\tTotal Loss: 56.8277\tAvg Loss: 0.0019\n",
      "Train Epoch: 38\t[35000/88956 (39%)]\tTotal Loss: 65.9469\tAvg Loss: 0.0019\n",
      "Train Epoch: 38\t[40000/88956 (45%)]\tTotal Loss: 75.2487\tAvg Loss: 0.0019\n",
      "Train Epoch: 38\t[45000/88956 (51%)]\tTotal Loss: 84.6048\tAvg Loss: 0.0019\n",
      "Train Epoch: 38\t[50000/88956 (56%)]\tTotal Loss: 94.7488\tAvg Loss: 0.0019\n",
      "Train Epoch: 38\t[55000/88956 (62%)]\tTotal Loss: 104.3016\tAvg Loss: 0.0019\n",
      "Train Epoch: 38\t[60000/88956 (67%)]\tTotal Loss: 113.3933\tAvg Loss: 0.0019\n",
      "Train Epoch: 38\t[65000/88956 (73%)]\tTotal Loss: 123.3925\tAvg Loss: 0.0019\n",
      "Train Epoch: 38\t[70000/88956 (79%)]\tTotal Loss: 132.5031\tAvg Loss: 0.0019\n",
      "Train Epoch: 38\t[75000/88956 (84%)]\tTotal Loss: 142.7387\tAvg Loss: 0.0019\n",
      "Train Epoch: 38\t[80000/88956 (90%)]\tTotal Loss: 151.6506\tAvg Loss: 0.0019\n",
      "Train Epoch: 38\t[85000/88956 (96%)]\tTotal Loss: 160.5830\tAvg Loss: 0.0019\n",
      "====> Epoch: 38\tTotal Loss: 168.1964\t Avg Loss: 0.0019\t Fx Loss: 154.0672\t Set Loss: 14.1291\n",
      "\t\tCorrect: 34934/88956\tFx Correct: 79032/88956\tSet Correct: 37696/88956\n",
      "\t\tPercentage Correct: 39.27\tPercentage Fx Correct: 88.84\tPercentage Set Correct: 42.38\n",
      "====> Val Loss: 23.6675\t Avg Loss: 0.0024\t Fx Loss: 21.4146\t Set Loss: 2.2529\n",
      "\t\tCorrect: 3598/9885\tFx Correct: 8574/9885\tSet Correct: 3941/9885\n",
      "\t\tPercentage Correct: 36.40\tPercentage Fx Correct: 86.74\tPercentage Set Correct: 39.87\n",
      "====> Test Loss: 59.3985\t Avg Loss: 0.0024\t Fx Loss: 53.6569\t Set Loss: 5.7416\n",
      "\t\tCorrect: 9147/24711\tFx Correct: 21588/24711\tSet Correct: 9927/24711\n",
      "\t\tPercentage Correct: 37.02\tPercentage Fx Correct: 87.36\tPercentage Set Correct: 40.17\n",
      "Train Epoch: 39\t[5000/88956 (6%)]\tTotal Loss: 9.0242\tAvg Loss: 0.0018\n",
      "Train Epoch: 39\t[10000/88956 (11%)]\tTotal Loss: 18.4419\tAvg Loss: 0.0018\n",
      "Train Epoch: 39\t[15000/88956 (17%)]\tTotal Loss: 27.8027\tAvg Loss: 0.0019\n",
      "Train Epoch: 39\t[20000/88956 (22%)]\tTotal Loss: 36.8011\tAvg Loss: 0.0018\n",
      "Train Epoch: 39\t[25000/88956 (28%)]\tTotal Loss: 45.2237\tAvg Loss: 0.0018\n",
      "Train Epoch: 39\t[30000/88956 (34%)]\tTotal Loss: 54.7390\tAvg Loss: 0.0018\n",
      "Train Epoch: 39\t[35000/88956 (39%)]\tTotal Loss: 63.9861\tAvg Loss: 0.0018\n",
      "Train Epoch: 39\t[40000/88956 (45%)]\tTotal Loss: 73.3922\tAvg Loss: 0.0018\n",
      "Train Epoch: 39\t[45000/88956 (51%)]\tTotal Loss: 82.3988\tAvg Loss: 0.0018\n",
      "Train Epoch: 39\t[50000/88956 (56%)]\tTotal Loss: 91.8308\tAvg Loss: 0.0018\n",
      "Train Epoch: 39\t[55000/88956 (62%)]\tTotal Loss: 100.7323\tAvg Loss: 0.0018\n",
      "Train Epoch: 39\t[60000/88956 (67%)]\tTotal Loss: 110.1818\tAvg Loss: 0.0018\n",
      "Train Epoch: 39\t[65000/88956 (73%)]\tTotal Loss: 119.1211\tAvg Loss: 0.0018\n",
      "Train Epoch: 39\t[70000/88956 (79%)]\tTotal Loss: 128.2858\tAvg Loss: 0.0018\n",
      "Train Epoch: 39\t[75000/88956 (84%)]\tTotal Loss: 137.5226\tAvg Loss: 0.0018\n",
      "Train Epoch: 39\t[80000/88956 (90%)]\tTotal Loss: 147.1830\tAvg Loss: 0.0018\n",
      "Train Epoch: 39\t[85000/88956 (96%)]\tTotal Loss: 156.2844\tAvg Loss: 0.0018\n",
      "====> Epoch: 39\tTotal Loss: 163.3053\t Avg Loss: 0.0018\t Fx Loss: 149.7145\t Set Loss: 13.5908\n",
      "\t\tCorrect: 35606/88956\tFx Correct: 79110/88956\tSet Correct: 38449/88956\n",
      "\t\tPercentage Correct: 40.03\tPercentage Fx Correct: 88.93\tPercentage Set Correct: 43.22\n",
      "====> Val Loss: 21.1438\t Avg Loss: 0.0021\t Fx Loss: 19.2984\t Set Loss: 1.8454\n",
      "\t\tCorrect: 3886/9885\tFx Correct: 8668/9885\tSet Correct: 4184/9885\n",
      "\t\tPercentage Correct: 39.31\tPercentage Fx Correct: 87.69\tPercentage Set Correct: 42.33\n",
      "====> Test Loss: 50.7770\t Avg Loss: 0.0021\t Fx Loss: 46.2808\t Set Loss: 4.4962\n",
      "\t\tCorrect: 9554/24711\tFx Correct: 21874/24711\tSet Correct: 10250/24711\n",
      "\t\tPercentage Correct: 38.66\tPercentage Fx Correct: 88.52\tPercentage Set Correct: 41.48\n",
      "Train Epoch: 40\t[5000/88956 (6%)]\tTotal Loss: 9.3893\tAvg Loss: 0.0019\n",
      "Train Epoch: 40\t[10000/88956 (11%)]\tTotal Loss: 18.1143\tAvg Loss: 0.0018\n",
      "Train Epoch: 40\t[15000/88956 (17%)]\tTotal Loss: 27.4241\tAvg Loss: 0.0018\n",
      "Train Epoch: 40\t[20000/88956 (22%)]\tTotal Loss: 36.5528\tAvg Loss: 0.0018\n",
      "Train Epoch: 40\t[25000/88956 (28%)]\tTotal Loss: 45.7042\tAvg Loss: 0.0018\n",
      "Train Epoch: 40\t[30000/88956 (34%)]\tTotal Loss: 54.9075\tAvg Loss: 0.0018\n",
      "Train Epoch: 40\t[35000/88956 (39%)]\tTotal Loss: 63.9152\tAvg Loss: 0.0018\n",
      "Train Epoch: 40\t[40000/88956 (45%)]\tTotal Loss: 73.1144\tAvg Loss: 0.0018\n",
      "Train Epoch: 40\t[45000/88956 (51%)]\tTotal Loss: 82.5247\tAvg Loss: 0.0018\n",
      "Train Epoch: 40\t[50000/88956 (56%)]\tTotal Loss: 91.9865\tAvg Loss: 0.0018\n",
      "Train Epoch: 40\t[55000/88956 (62%)]\tTotal Loss: 101.1387\tAvg Loss: 0.0018\n",
      "Train Epoch: 40\t[60000/88956 (67%)]\tTotal Loss: 110.1838\tAvg Loss: 0.0018\n",
      "Train Epoch: 40\t[65000/88956 (73%)]\tTotal Loss: 119.0499\tAvg Loss: 0.0018\n",
      "Train Epoch: 40\t[70000/88956 (79%)]\tTotal Loss: 128.7786\tAvg Loss: 0.0018\n",
      "Train Epoch: 40\t[75000/88956 (84%)]\tTotal Loss: 138.1379\tAvg Loss: 0.0018\n",
      "Train Epoch: 40\t[80000/88956 (90%)]\tTotal Loss: 147.4280\tAvg Loss: 0.0018\n",
      "Train Epoch: 40\t[85000/88956 (96%)]\tTotal Loss: 157.3217\tAvg Loss: 0.0019\n",
      "====> Epoch: 40\tTotal Loss: 164.9067\t Avg Loss: 0.0019\t Fx Loss: 151.1246\t Set Loss: 13.7821\n",
      "\t\tCorrect: 35423/88956\tFx Correct: 78998/88956\tSet Correct: 38251/88956\n",
      "\t\tPercentage Correct: 39.82\tPercentage Fx Correct: 88.81\tPercentage Set Correct: 43.00\n",
      "====> Val Loss: 21.9009\t Avg Loss: 0.0022\t Fx Loss: 20.0607\t Set Loss: 1.8402\n",
      "\t\tCorrect: 3895/9885\tFx Correct: 8660/9885\tSet Correct: 4185/9885\n",
      "\t\tPercentage Correct: 39.40\tPercentage Fx Correct: 87.61\tPercentage Set Correct: 42.34\n",
      "====> Test Loss: 51.8096\t Avg Loss: 0.0021\t Fx Loss: 47.3619\t Set Loss: 4.4477\n",
      "\t\tCorrect: 9956/24711\tFx Correct: 21880/24711\tSet Correct: 10678/24711\n",
      "\t\tPercentage Correct: 40.29\tPercentage Fx Correct: 88.54\tPercentage Set Correct: 43.21\n",
      "\n",
      "=== saved best model ===\n",
      "\n",
      "Train Epoch: 41\t[5000/88956 (6%)]\tTotal Loss: 9.3173\tAvg Loss: 0.0019\n",
      "Train Epoch: 41\t[10000/88956 (11%)]\tTotal Loss: 18.6556\tAvg Loss: 0.0019\n",
      "Train Epoch: 41\t[15000/88956 (17%)]\tTotal Loss: 27.4507\tAvg Loss: 0.0018\n",
      "Train Epoch: 41\t[20000/88956 (22%)]\tTotal Loss: 36.1583\tAvg Loss: 0.0018\n",
      "Train Epoch: 41\t[25000/88956 (28%)]\tTotal Loss: 45.4052\tAvg Loss: 0.0018\n",
      "Train Epoch: 41\t[30000/88956 (34%)]\tTotal Loss: 54.0801\tAvg Loss: 0.0018\n",
      "Train Epoch: 41\t[35000/88956 (39%)]\tTotal Loss: 64.0557\tAvg Loss: 0.0018\n",
      "Train Epoch: 41\t[40000/88956 (45%)]\tTotal Loss: 73.3234\tAvg Loss: 0.0018\n",
      "Train Epoch: 41\t[45000/88956 (51%)]\tTotal Loss: 82.5006\tAvg Loss: 0.0018\n",
      "Train Epoch: 41\t[50000/88956 (56%)]\tTotal Loss: 91.2695\tAvg Loss: 0.0018\n",
      "Train Epoch: 41\t[55000/88956 (62%)]\tTotal Loss: 99.9471\tAvg Loss: 0.0018\n",
      "Train Epoch: 41\t[60000/88956 (67%)]\tTotal Loss: 109.0936\tAvg Loss: 0.0018\n",
      "Train Epoch: 41\t[65000/88956 (73%)]\tTotal Loss: 118.2186\tAvg Loss: 0.0018\n",
      "Train Epoch: 41\t[70000/88956 (79%)]\tTotal Loss: 127.3124\tAvg Loss: 0.0018\n",
      "Train Epoch: 41\t[75000/88956 (84%)]\tTotal Loss: 135.9733\tAvg Loss: 0.0018\n",
      "Train Epoch: 41\t[80000/88956 (90%)]\tTotal Loss: 145.3842\tAvg Loss: 0.0018\n",
      "Train Epoch: 41\t[85000/88956 (96%)]\tTotal Loss: 155.0792\tAvg Loss: 0.0018\n",
      "====> Epoch: 41\tTotal Loss: 163.0486\t Avg Loss: 0.0018\t Fx Loss: 149.5979\t Set Loss: 13.4507\n",
      "\t\tCorrect: 35951/88956\tFx Correct: 79072/88956\tSet Correct: 38739/88956\n",
      "\t\tPercentage Correct: 40.41\tPercentage Fx Correct: 88.89\tPercentage Set Correct: 43.55\n",
      "====> Val Loss: 21.8966\t Avg Loss: 0.0022\t Fx Loss: 19.9330\t Set Loss: 1.9636\n",
      "\t\tCorrect: 3787/9885\tFx Correct: 8677/9885\tSet Correct: 4114/9885\n",
      "\t\tPercentage Correct: 38.31\tPercentage Fx Correct: 87.78\tPercentage Set Correct: 41.62\n",
      "====> Test Loss: 54.4453\t Avg Loss: 0.0022\t Fx Loss: 49.4605\t Set Loss: 4.9848\n",
      "\t\tCorrect: 9399/24711\tFx Correct: 21538/24711\tSet Correct: 10218/24711\n",
      "\t\tPercentage Correct: 38.04\tPercentage Fx Correct: 87.16\tPercentage Set Correct: 41.35\n",
      "Train Epoch: 42\t[5000/88956 (6%)]\tTotal Loss: 9.5163\tAvg Loss: 0.0019\n",
      "Train Epoch: 42\t[10000/88956 (11%)]\tTotal Loss: 18.3869\tAvg Loss: 0.0018\n",
      "Train Epoch: 42\t[15000/88956 (17%)]\tTotal Loss: 26.9218\tAvg Loss: 0.0018\n",
      "Train Epoch: 42\t[20000/88956 (22%)]\tTotal Loss: 36.8204\tAvg Loss: 0.0018\n",
      "Train Epoch: 42\t[25000/88956 (28%)]\tTotal Loss: 46.2336\tAvg Loss: 0.0018\n",
      "Train Epoch: 42\t[30000/88956 (34%)]\tTotal Loss: 54.8811\tAvg Loss: 0.0018\n",
      "Train Epoch: 42\t[35000/88956 (39%)]\tTotal Loss: 64.0435\tAvg Loss: 0.0018\n",
      "Train Epoch: 42\t[40000/88956 (45%)]\tTotal Loss: 73.0691\tAvg Loss: 0.0018\n",
      "Train Epoch: 42\t[45000/88956 (51%)]\tTotal Loss: 82.2925\tAvg Loss: 0.0018\n",
      "Train Epoch: 42\t[50000/88956 (56%)]\tTotal Loss: 91.3833\tAvg Loss: 0.0018\n",
      "Train Epoch: 42\t[55000/88956 (62%)]\tTotal Loss: 100.8361\tAvg Loss: 0.0018\n",
      "Train Epoch: 42\t[60000/88956 (67%)]\tTotal Loss: 109.7672\tAvg Loss: 0.0018\n",
      "Train Epoch: 42\t[65000/88956 (73%)]\tTotal Loss: 118.7645\tAvg Loss: 0.0018\n",
      "Train Epoch: 42\t[70000/88956 (79%)]\tTotal Loss: 127.9470\tAvg Loss: 0.0018\n",
      "Train Epoch: 42\t[75000/88956 (84%)]\tTotal Loss: 137.3623\tAvg Loss: 0.0018\n",
      "Train Epoch: 42\t[80000/88956 (90%)]\tTotal Loss: 146.5157\tAvg Loss: 0.0018\n",
      "Train Epoch: 42\t[85000/88956 (96%)]\tTotal Loss: 155.4276\tAvg Loss: 0.0018\n",
      "====> Epoch: 42\tTotal Loss: 163.4389\t Avg Loss: 0.0018\t Fx Loss: 150.1720\t Set Loss: 13.2669\n",
      "\t\tCorrect: 36289/88956\tFx Correct: 79139/88956\tSet Correct: 39173/88956\n",
      "\t\tPercentage Correct: 40.79\tPercentage Fx Correct: 88.96\tPercentage Set Correct: 44.04\n",
      "====> Val Loss: 22.9262\t Avg Loss: 0.0023\t Fx Loss: 21.0530\t Set Loss: 1.8732\n",
      "\t\tCorrect: 3776/9885\tFx Correct: 8654/9885\tSet Correct: 4099/9885\n",
      "\t\tPercentage Correct: 38.20\tPercentage Fx Correct: 87.55\tPercentage Set Correct: 41.47\n",
      "====> Test Loss: 57.9579\t Avg Loss: 0.0023\t Fx Loss: 53.2731\t Set Loss: 4.6848\n",
      "\t\tCorrect: 9321/24711\tFx Correct: 21521/24711\tSet Correct: 10222/24711\n",
      "\t\tPercentage Correct: 37.72\tPercentage Fx Correct: 87.09\tPercentage Set Correct: 41.37\n",
      "Train Epoch: 43\t[5000/88956 (6%)]\tTotal Loss: 9.5218\tAvg Loss: 0.0019\n",
      "Train Epoch: 43\t[10000/88956 (11%)]\tTotal Loss: 18.3537\tAvg Loss: 0.0018\n",
      "Train Epoch: 43\t[15000/88956 (17%)]\tTotal Loss: 27.3728\tAvg Loss: 0.0018\n",
      "Train Epoch: 43\t[20000/88956 (22%)]\tTotal Loss: 36.2750\tAvg Loss: 0.0018\n",
      "Train Epoch: 43\t[25000/88956 (28%)]\tTotal Loss: 45.4218\tAvg Loss: 0.0018\n",
      "Train Epoch: 43\t[30000/88956 (34%)]\tTotal Loss: 55.0468\tAvg Loss: 0.0018\n",
      "Train Epoch: 43\t[35000/88956 (39%)]\tTotal Loss: 63.6909\tAvg Loss: 0.0018\n",
      "Train Epoch: 43\t[40000/88956 (45%)]\tTotal Loss: 72.4931\tAvg Loss: 0.0018\n",
      "Train Epoch: 43\t[45000/88956 (51%)]\tTotal Loss: 81.2398\tAvg Loss: 0.0018\n",
      "Train Epoch: 43\t[50000/88956 (56%)]\tTotal Loss: 90.0628\tAvg Loss: 0.0018\n",
      "Train Epoch: 43\t[55000/88956 (62%)]\tTotal Loss: 98.6177\tAvg Loss: 0.0018\n",
      "Train Epoch: 43\t[60000/88956 (67%)]\tTotal Loss: 107.3815\tAvg Loss: 0.0018\n",
      "Train Epoch: 43\t[65000/88956 (73%)]\tTotal Loss: 116.8538\tAvg Loss: 0.0018\n",
      "Train Epoch: 43\t[70000/88956 (79%)]\tTotal Loss: 126.5084\tAvg Loss: 0.0018\n",
      "Train Epoch: 43\t[75000/88956 (84%)]\tTotal Loss: 135.3268\tAvg Loss: 0.0018\n",
      "Train Epoch: 43\t[80000/88956 (90%)]\tTotal Loss: 144.1182\tAvg Loss: 0.0018\n",
      "Train Epoch: 43\t[85000/88956 (96%)]\tTotal Loss: 152.9949\tAvg Loss: 0.0018\n",
      "====> Epoch: 43\tTotal Loss: 161.3321\t Avg Loss: 0.0018\t Fx Loss: 148.2379\t Set Loss: 13.0941\n",
      "\t\tCorrect: 36581/88956\tFx Correct: 79195/88956\tSet Correct: 39451/88956\n",
      "\t\tPercentage Correct: 41.12\tPercentage Fx Correct: 89.03\tPercentage Set Correct: 44.35\n",
      "====> Val Loss: 22.0786\t Avg Loss: 0.0022\t Fx Loss: 20.2422\t Set Loss: 1.8363\n",
      "\t\tCorrect: 3851/9885\tFx Correct: 8662/9885\tSet Correct: 4165/9885\n",
      "\t\tPercentage Correct: 38.96\tPercentage Fx Correct: 87.63\tPercentage Set Correct: 42.13\n",
      "====> Test Loss: 54.9188\t Avg Loss: 0.0022\t Fx Loss: 50.3988\t Set Loss: 4.5200\n",
      "\t\tCorrect: 9791/24711\tFx Correct: 21610/24711\tSet Correct: 10694/24711\n",
      "\t\tPercentage Correct: 39.62\tPercentage Fx Correct: 87.45\tPercentage Set Correct: 43.28\n",
      "Train Epoch: 44\t[5000/88956 (6%)]\tTotal Loss: 9.0171\tAvg Loss: 0.0018\n",
      "Train Epoch: 44\t[10000/88956 (11%)]\tTotal Loss: 17.9580\tAvg Loss: 0.0018\n",
      "Train Epoch: 44\t[15000/88956 (17%)]\tTotal Loss: 26.9142\tAvg Loss: 0.0018\n",
      "Train Epoch: 44\t[20000/88956 (22%)]\tTotal Loss: 35.9329\tAvg Loss: 0.0018\n",
      "Train Epoch: 44\t[25000/88956 (28%)]\tTotal Loss: 44.7360\tAvg Loss: 0.0018\n",
      "Train Epoch: 44\t[30000/88956 (34%)]\tTotal Loss: 53.3893\tAvg Loss: 0.0018\n",
      "Train Epoch: 44\t[35000/88956 (39%)]\tTotal Loss: 62.3625\tAvg Loss: 0.0018\n",
      "Train Epoch: 44\t[40000/88956 (45%)]\tTotal Loss: 71.5614\tAvg Loss: 0.0018\n",
      "Train Epoch: 44\t[45000/88956 (51%)]\tTotal Loss: 80.6603\tAvg Loss: 0.0018\n",
      "Train Epoch: 44\t[50000/88956 (56%)]\tTotal Loss: 89.1247\tAvg Loss: 0.0018\n",
      "Train Epoch: 44\t[55000/88956 (62%)]\tTotal Loss: 98.2320\tAvg Loss: 0.0018\n",
      "Train Epoch: 44\t[60000/88956 (67%)]\tTotal Loss: 107.4397\tAvg Loss: 0.0018\n",
      "Train Epoch: 44\t[65000/88956 (73%)]\tTotal Loss: 116.4177\tAvg Loss: 0.0018\n",
      "Train Epoch: 44\t[70000/88956 (79%)]\tTotal Loss: 125.0716\tAvg Loss: 0.0018\n",
      "Train Epoch: 44\t[75000/88956 (84%)]\tTotal Loss: 134.2609\tAvg Loss: 0.0018\n",
      "Train Epoch: 44\t[80000/88956 (90%)]\tTotal Loss: 142.9898\tAvg Loss: 0.0018\n",
      "Train Epoch: 44\t[85000/88956 (96%)]\tTotal Loss: 152.3713\tAvg Loss: 0.0018\n",
      "====> Epoch: 44\tTotal Loss: 159.5995\t Avg Loss: 0.0018\t Fx Loss: 146.9831\t Set Loss: 12.6164\n",
      "\t\tCorrect: 36862/88956\tFx Correct: 79219/88956\tSet Correct: 39730/88956\n",
      "\t\tPercentage Correct: 41.44\tPercentage Fx Correct: 89.05\tPercentage Set Correct: 44.66\n",
      "====> Val Loss: 21.4861\t Avg Loss: 0.0022\t Fx Loss: 19.6958\t Set Loss: 1.7902\n",
      "\t\tCorrect: 3914/9885\tFx Correct: 8714/9885\tSet Correct: 4201/9885\n",
      "\t\tPercentage Correct: 39.60\tPercentage Fx Correct: 88.15\tPercentage Set Correct: 42.50\n",
      "====> Test Loss: 54.3312\t Avg Loss: 0.0022\t Fx Loss: 49.9317\t Set Loss: 4.3994\n",
      "\t\tCorrect: 9877/24711\tFx Correct: 21693/24711\tSet Correct: 10680/24711\n",
      "\t\tPercentage Correct: 39.97\tPercentage Fx Correct: 87.79\tPercentage Set Correct: 43.22\n",
      "\n",
      "=== saved best model ===\n",
      "\n",
      "Train Epoch: 45\t[5000/88956 (6%)]\tTotal Loss: 9.0042\tAvg Loss: 0.0018\n",
      "Train Epoch: 45\t[10000/88956 (11%)]\tTotal Loss: 18.2948\tAvg Loss: 0.0018\n",
      "Train Epoch: 45\t[15000/88956 (17%)]\tTotal Loss: 27.4819\tAvg Loss: 0.0018\n",
      "Train Epoch: 45\t[20000/88956 (22%)]\tTotal Loss: 36.2181\tAvg Loss: 0.0018\n",
      "Train Epoch: 45\t[25000/88956 (28%)]\tTotal Loss: 45.1815\tAvg Loss: 0.0018\n",
      "Train Epoch: 45\t[30000/88956 (34%)]\tTotal Loss: 53.9981\tAvg Loss: 0.0018\n",
      "Train Epoch: 45\t[35000/88956 (39%)]\tTotal Loss: 63.1217\tAvg Loss: 0.0018\n",
      "Train Epoch: 45\t[40000/88956 (45%)]\tTotal Loss: 71.9537\tAvg Loss: 0.0018\n",
      "Train Epoch: 45\t[45000/88956 (51%)]\tTotal Loss: 81.2406\tAvg Loss: 0.0018\n",
      "Train Epoch: 45\t[50000/88956 (56%)]\tTotal Loss: 90.1189\tAvg Loss: 0.0018\n",
      "Train Epoch: 45\t[55000/88956 (62%)]\tTotal Loss: 99.1560\tAvg Loss: 0.0018\n",
      "Train Epoch: 45\t[60000/88956 (67%)]\tTotal Loss: 108.3476\tAvg Loss: 0.0018\n",
      "Train Epoch: 45\t[65000/88956 (73%)]\tTotal Loss: 117.9271\tAvg Loss: 0.0018\n",
      "Train Epoch: 45\t[70000/88956 (79%)]\tTotal Loss: 126.2949\tAvg Loss: 0.0018\n",
      "Train Epoch: 45\t[75000/88956 (84%)]\tTotal Loss: 135.8184\tAvg Loss: 0.0018\n",
      "Train Epoch: 45\t[80000/88956 (90%)]\tTotal Loss: 144.3924\tAvg Loss: 0.0018\n",
      "Train Epoch: 45\t[85000/88956 (96%)]\tTotal Loss: 153.5376\tAvg Loss: 0.0018\n",
      "====> Epoch: 45\tTotal Loss: 160.9305\t Avg Loss: 0.0018\t Fx Loss: 148.1172\t Set Loss: 12.8133\n",
      "\t\tCorrect: 36792/88956\tFx Correct: 79177/88956\tSet Correct: 39723/88956\n",
      "\t\tPercentage Correct: 41.36\tPercentage Fx Correct: 89.01\tPercentage Set Correct: 44.65\n",
      "====> Val Loss: 20.5390\t Avg Loss: 0.0021\t Fx Loss: 18.7266\t Set Loss: 1.8123\n",
      "\t\tCorrect: 3811/9885\tFx Correct: 8720/9885\tSet Correct: 4103/9885\n",
      "\t\tPercentage Correct: 38.55\tPercentage Fx Correct: 88.21\tPercentage Set Correct: 41.51\n",
      "====> Test Loss: 51.1631\t Avg Loss: 0.0021\t Fx Loss: 46.6007\t Set Loss: 4.5623\n",
      "\t\tCorrect: 9486/24711\tFx Correct: 21709/24711\tSet Correct: 10289/24711\n",
      "\t\tPercentage Correct: 38.39\tPercentage Fx Correct: 87.85\tPercentage Set Correct: 41.64\n",
      "Train Epoch: 46\t[5000/88956 (6%)]\tTotal Loss: 8.8834\tAvg Loss: 0.0018\n",
      "Train Epoch: 46\t[10000/88956 (11%)]\tTotal Loss: 17.4294\tAvg Loss: 0.0017\n",
      "Train Epoch: 46\t[15000/88956 (17%)]\tTotal Loss: 26.2050\tAvg Loss: 0.0017\n",
      "Train Epoch: 46\t[20000/88956 (22%)]\tTotal Loss: 34.7692\tAvg Loss: 0.0017\n",
      "Train Epoch: 46\t[25000/88956 (28%)]\tTotal Loss: 44.2877\tAvg Loss: 0.0018\n",
      "Train Epoch: 46\t[30000/88956 (34%)]\tTotal Loss: 52.9006\tAvg Loss: 0.0018\n",
      "Train Epoch: 46\t[35000/88956 (39%)]\tTotal Loss: 61.2883\tAvg Loss: 0.0018\n",
      "Train Epoch: 46\t[40000/88956 (45%)]\tTotal Loss: 69.7876\tAvg Loss: 0.0017\n",
      "Train Epoch: 46\t[45000/88956 (51%)]\tTotal Loss: 79.0927\tAvg Loss: 0.0018\n",
      "Train Epoch: 46\t[50000/88956 (56%)]\tTotal Loss: 88.2019\tAvg Loss: 0.0018\n",
      "Train Epoch: 46\t[55000/88956 (62%)]\tTotal Loss: 97.2022\tAvg Loss: 0.0018\n",
      "Train Epoch: 46\t[60000/88956 (67%)]\tTotal Loss: 105.6244\tAvg Loss: 0.0018\n",
      "Train Epoch: 46\t[65000/88956 (73%)]\tTotal Loss: 113.9601\tAvg Loss: 0.0018\n",
      "Train Epoch: 46\t[70000/88956 (79%)]\tTotal Loss: 122.9501\tAvg Loss: 0.0018\n",
      "Train Epoch: 46\t[75000/88956 (84%)]\tTotal Loss: 132.0579\tAvg Loss: 0.0018\n",
      "Train Epoch: 46\t[80000/88956 (90%)]\tTotal Loss: 141.0839\tAvg Loss: 0.0018\n",
      "Train Epoch: 46\t[85000/88956 (96%)]\tTotal Loss: 150.0563\tAvg Loss: 0.0018\n",
      "====> Epoch: 46\tTotal Loss: 157.0800\t Avg Loss: 0.0018\t Fx Loss: 144.8693\t Set Loss: 12.2107\n",
      "\t\tCorrect: 37342/88956\tFx Correct: 79242/88956\tSet Correct: 40319/88956\n",
      "\t\tPercentage Correct: 41.98\tPercentage Fx Correct: 89.08\tPercentage Set Correct: 45.32\n",
      "====> Val Loss: 21.7734\t Avg Loss: 0.0022\t Fx Loss: 19.9908\t Set Loss: 1.7826\n",
      "\t\tCorrect: 4030/9885\tFx Correct: 8696/9885\tSet Correct: 4395/9885\n",
      "\t\tPercentage Correct: 40.77\tPercentage Fx Correct: 87.97\tPercentage Set Correct: 44.46\n",
      "====> Test Loss: 53.0830\t Avg Loss: 0.0021\t Fx Loss: 48.8188\t Set Loss: 4.2642\n",
      "\t\tCorrect: 10017/24711\tFx Correct: 21663/24711\tSet Correct: 10972/24711\n",
      "\t\tPercentage Correct: 40.54\tPercentage Fx Correct: 87.67\tPercentage Set Correct: 44.40\n",
      "\n",
      "=== saved best model ===\n",
      "\n",
      "Train Epoch: 47\t[5000/88956 (6%)]\tTotal Loss: 8.9958\tAvg Loss: 0.0018\n",
      "Train Epoch: 47\t[10000/88956 (11%)]\tTotal Loss: 17.6948\tAvg Loss: 0.0018\n",
      "Train Epoch: 47\t[15000/88956 (17%)]\tTotal Loss: 26.7119\tAvg Loss: 0.0018\n",
      "Train Epoch: 47\t[20000/88956 (22%)]\tTotal Loss: 35.8413\tAvg Loss: 0.0018\n",
      "Train Epoch: 47\t[25000/88956 (28%)]\tTotal Loss: 44.2793\tAvg Loss: 0.0018\n",
      "Train Epoch: 47\t[30000/88956 (34%)]\tTotal Loss: 53.4406\tAvg Loss: 0.0018\n",
      "Train Epoch: 47\t[35000/88956 (39%)]\tTotal Loss: 61.6471\tAvg Loss: 0.0018\n",
      "Train Epoch: 47\t[40000/88956 (45%)]\tTotal Loss: 71.0049\tAvg Loss: 0.0018\n",
      "Train Epoch: 47\t[45000/88956 (51%)]\tTotal Loss: 79.7101\tAvg Loss: 0.0018\n",
      "Train Epoch: 47\t[50000/88956 (56%)]\tTotal Loss: 88.6247\tAvg Loss: 0.0018\n",
      "Train Epoch: 47\t[55000/88956 (62%)]\tTotal Loss: 97.2846\tAvg Loss: 0.0018\n",
      "Train Epoch: 47\t[60000/88956 (67%)]\tTotal Loss: 105.9853\tAvg Loss: 0.0018\n",
      "Train Epoch: 47\t[65000/88956 (73%)]\tTotal Loss: 114.5128\tAvg Loss: 0.0018\n",
      "Train Epoch: 47\t[70000/88956 (79%)]\tTotal Loss: 124.4010\tAvg Loss: 0.0018\n",
      "Train Epoch: 47\t[75000/88956 (84%)]\tTotal Loss: 133.0941\tAvg Loss: 0.0018\n",
      "Train Epoch: 47\t[80000/88956 (90%)]\tTotal Loss: 141.9367\tAvg Loss: 0.0018\n",
      "Train Epoch: 47\t[85000/88956 (96%)]\tTotal Loss: 150.7169\tAvg Loss: 0.0018\n",
      "====> Epoch: 47\tTotal Loss: 157.8059\t Avg Loss: 0.0018\t Fx Loss: 145.5266\t Set Loss: 12.2793\n",
      "\t\tCorrect: 37380/88956\tFx Correct: 79268/88956\tSet Correct: 40334/88956\n",
      "\t\tPercentage Correct: 42.02\tPercentage Fx Correct: 89.11\tPercentage Set Correct: 45.34\n",
      "====> Val Loss: 21.0739\t Avg Loss: 0.0021\t Fx Loss: 19.2979\t Set Loss: 1.7760\n",
      "\t\tCorrect: 3961/9885\tFx Correct: 8714/9885\tSet Correct: 4281/9885\n",
      "\t\tPercentage Correct: 40.07\tPercentage Fx Correct: 88.15\tPercentage Set Correct: 43.31\n",
      "====> Test Loss: 51.0326\t Avg Loss: 0.0021\t Fx Loss: 46.8844\t Set Loss: 4.1482\n",
      "\t\tCorrect: 9796/24711\tFx Correct: 21756/24711\tSet Correct: 10694/24711\n",
      "\t\tPercentage Correct: 39.64\tPercentage Fx Correct: 88.04\tPercentage Set Correct: 43.28\n",
      "Train Epoch: 48\t[5000/88956 (6%)]\tTotal Loss: 9.3908\tAvg Loss: 0.0019\n",
      "Train Epoch: 48\t[10000/88956 (11%)]\tTotal Loss: 18.4974\tAvg Loss: 0.0018\n",
      "Train Epoch: 48\t[15000/88956 (17%)]\tTotal Loss: 27.3437\tAvg Loss: 0.0018\n",
      "Train Epoch: 48\t[20000/88956 (22%)]\tTotal Loss: 35.9520\tAvg Loss: 0.0018\n",
      "Train Epoch: 48\t[25000/88956 (28%)]\tTotal Loss: 45.3372\tAvg Loss: 0.0018\n",
      "Train Epoch: 48\t[30000/88956 (34%)]\tTotal Loss: 54.5728\tAvg Loss: 0.0018\n",
      "Train Epoch: 48\t[35000/88956 (39%)]\tTotal Loss: 63.2220\tAvg Loss: 0.0018\n",
      "Train Epoch: 48\t[40000/88956 (45%)]\tTotal Loss: 72.1257\tAvg Loss: 0.0018\n",
      "Train Epoch: 48\t[45000/88956 (51%)]\tTotal Loss: 81.0355\tAvg Loss: 0.0018\n",
      "Train Epoch: 48\t[50000/88956 (56%)]\tTotal Loss: 89.7726\tAvg Loss: 0.0018\n",
      "Train Epoch: 48\t[55000/88956 (62%)]\tTotal Loss: 99.0568\tAvg Loss: 0.0018\n",
      "Train Epoch: 48\t[60000/88956 (67%)]\tTotal Loss: 107.8643\tAvg Loss: 0.0018\n",
      "Train Epoch: 48\t[65000/88956 (73%)]\tTotal Loss: 116.4921\tAvg Loss: 0.0018\n",
      "Train Epoch: 48\t[70000/88956 (79%)]\tTotal Loss: 125.0916\tAvg Loss: 0.0018\n",
      "Train Epoch: 48\t[75000/88956 (84%)]\tTotal Loss: 134.3544\tAvg Loss: 0.0018\n",
      "Train Epoch: 48\t[80000/88956 (90%)]\tTotal Loss: 143.6257\tAvg Loss: 0.0018\n",
      "Train Epoch: 48\t[85000/88956 (96%)]\tTotal Loss: 152.4227\tAvg Loss: 0.0018\n",
      "====> Epoch: 48\tTotal Loss: 158.8297\t Avg Loss: 0.0018\t Fx Loss: 146.4920\t Set Loss: 12.3377\n",
      "\t\tCorrect: 37085/88956\tFx Correct: 79349/88956\tSet Correct: 40050/88956\n",
      "\t\tPercentage Correct: 41.69\tPercentage Fx Correct: 89.20\tPercentage Set Correct: 45.02\n",
      "====> Val Loss: 20.0154\t Avg Loss: 0.0020\t Fx Loss: 18.3940\t Set Loss: 1.6213\n",
      "\t\tCorrect: 4188/9885\tFx Correct: 8726/9885\tSet Correct: 4495/9885\n",
      "\t\tPercentage Correct: 42.37\tPercentage Fx Correct: 88.28\tPercentage Set Correct: 45.47\n",
      "====> Test Loss: 48.5230\t Avg Loss: 0.0020\t Fx Loss: 44.6001\t Set Loss: 3.9229\n",
      "\t\tCorrect: 10554/24711\tFx Correct: 21769/24711\tSet Correct: 11359/24711\n",
      "\t\tPercentage Correct: 42.71\tPercentage Fx Correct: 88.09\tPercentage Set Correct: 45.97\n",
      "\n",
      "=== saved best model ===\n",
      "\n",
      "Train Epoch: 49\t[5000/88956 (6%)]\tTotal Loss: 8.8997\tAvg Loss: 0.0018\n",
      "Train Epoch: 49\t[10000/88956 (11%)]\tTotal Loss: 17.1223\tAvg Loss: 0.0017\n",
      "Train Epoch: 49\t[15000/88956 (17%)]\tTotal Loss: 25.8257\tAvg Loss: 0.0017\n",
      "Train Epoch: 49\t[20000/88956 (22%)]\tTotal Loss: 35.3764\tAvg Loss: 0.0018\n",
      "Train Epoch: 49\t[25000/88956 (28%)]\tTotal Loss: 44.2782\tAvg Loss: 0.0018\n",
      "Train Epoch: 49\t[30000/88956 (34%)]\tTotal Loss: 53.0130\tAvg Loss: 0.0018\n",
      "Train Epoch: 49\t[35000/88956 (39%)]\tTotal Loss: 61.9658\tAvg Loss: 0.0018\n",
      "Train Epoch: 49\t[40000/88956 (45%)]\tTotal Loss: 71.1427\tAvg Loss: 0.0018\n",
      "Train Epoch: 49\t[45000/88956 (51%)]\tTotal Loss: 79.9294\tAvg Loss: 0.0018\n",
      "Train Epoch: 49\t[50000/88956 (56%)]\tTotal Loss: 88.5731\tAvg Loss: 0.0018\n",
      "Train Epoch: 49\t[55000/88956 (62%)]\tTotal Loss: 97.6442\tAvg Loss: 0.0018\n",
      "Train Epoch: 49\t[60000/88956 (67%)]\tTotal Loss: 107.6006\tAvg Loss: 0.0018\n",
      "Train Epoch: 49\t[65000/88956 (73%)]\tTotal Loss: 116.7295\tAvg Loss: 0.0018\n",
      "Train Epoch: 49\t[70000/88956 (79%)]\tTotal Loss: 125.6267\tAvg Loss: 0.0018\n",
      "Train Epoch: 49\t[75000/88956 (84%)]\tTotal Loss: 134.7335\tAvg Loss: 0.0018\n",
      "Train Epoch: 49\t[80000/88956 (90%)]\tTotal Loss: 143.2391\tAvg Loss: 0.0018\n",
      "Train Epoch: 49\t[85000/88956 (96%)]\tTotal Loss: 153.3297\tAvg Loss: 0.0018\n",
      "====> Epoch: 49\tTotal Loss: 160.2883\t Avg Loss: 0.0018\t Fx Loss: 147.8056\t Set Loss: 12.4827\n",
      "\t\tCorrect: 37127/88956\tFx Correct: 79273/88956\tSet Correct: 40061/88956\n",
      "\t\tPercentage Correct: 41.74\tPercentage Fx Correct: 89.11\tPercentage Set Correct: 45.03\n",
      "====> Val Loss: 20.7051\t Avg Loss: 0.0021\t Fx Loss: 18.9689\t Set Loss: 1.7362\n",
      "\t\tCorrect: 3931/9885\tFx Correct: 8719/9885\tSet Correct: 4255/9885\n",
      "\t\tPercentage Correct: 39.77\tPercentage Fx Correct: 88.20\tPercentage Set Correct: 43.05\n",
      "====> Test Loss: 50.1375\t Avg Loss: 0.0020\t Fx Loss: 45.9125\t Set Loss: 4.2250\n",
      "\t\tCorrect: 9864/24711\tFx Correct: 21713/24711\tSet Correct: 10646/24711\n",
      "\t\tPercentage Correct: 39.92\tPercentage Fx Correct: 87.87\tPercentage Set Correct: 43.08\n",
      "Training time: 53319.657662153244s\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T01:46:56.385156Z",
     "start_time": "2024-09-13T01:46:56.356951Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# BEST RESULTS\n",
    "print('Accuracy: ', 100 * max(all_train_correct) / train_set_size)\n",
    "print('Epoch: ', np.argmax(all_train_correct))\n",
    "print()\n",
    "print('Accuracy: ', 100 * max(all_val_correct) / val_set_size)\n",
    "print('Epoch: ', np.argmax(all_val_correct))\n",
    "print()\n",
    "print('Accuracy: ', 100 * max(all_test_correct) / test_set_size)\n",
    "print('Epoch: ', np.argmax(all_test_correct))\n",
    "print()"
   ],
   "id": "33e6fa8c2059895",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  42.02077431539188\n",
      "Epoch:  47\n",
      "\n",
      "Accuracy:  42.36722306525038\n",
      "Epoch:  48\n",
      "\n",
      "Accuracy:  42.70972441422848\n",
      "Epoch:  48\n",
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T01:49:24.230972Z",
     "start_time": "2024-09-13T01:49:23.415797Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# SAVE RESULTS - all losses, all correct, best results\n",
    "all_train_losses_npy = np.array(all_train_losses, dtype=object)\n",
    "all_train_correct_npy = np.array(all_train_correct, dtype=object)\n",
    "best_train_results_npy = np.array(all_train_results[43], dtype=object)\n",
    "\n",
    "all_val_losses_npy = np.array(all_val_losses, dtype=object)\n",
    "all_val_correct_npy = np.array(all_val_correct, dtype=object)\n",
    "best_val_results_npy = np.array(all_val_results[33], dtype=object)\n",
    "\n",
    "all_test_losses_npy = np.array(all_test_losses, dtype=object)\n",
    "all_test_correct_npy = np.array(all_test_correct, dtype=object)\n",
    "best_test_results_npy = np.array(all_test_results[39], dtype=object)\n",
    "\n",
    "fx_labels_npy = np.array(list(dataset.fx_to_label.keys()), dtype=object)\n",
    "\n",
    "np.save(file=('%s/%s/%s' % (results_folder, results_subfolder, 'all_train_losses')), arr=all_train_losses_npy)\n",
    "np.save(file=('%s/%s/%s' % (results_folder, results_subfolder, 'all_train_correct')), arr=all_train_correct_npy)\n",
    "np.save(file=('%s/%s/%s' % (results_folder, results_subfolder, 'best_train_results')), arr=best_train_results_npy)\n",
    "\n",
    "np.save(file=('%s/%s/%s' % (results_folder, results_subfolder, 'all_val_losses')), arr=all_val_losses_npy)\n",
    "np.save(file=('%s/%s/%s' % (results_folder, results_subfolder, 'all_val_correct')), arr=all_val_correct_npy)\n",
    "np.save(file=('%s/%s/%s' % (results_folder, results_subfolder, 'best_val_results')), arr=best_val_results_npy)\n",
    "\n",
    "np.save(file=('%s/%s/%s' % (results_folder, results_subfolder, 'all_test_losses')), arr=all_test_losses_npy)\n",
    "np.save(file=('%s/%s/%s' % (results_folder, results_subfolder, 'all_test_correct')), arr=all_test_correct_npy)\n",
    "np.save(file=('%s/%s/%s' % (results_folder, results_subfolder, 'best_test_results')), arr=best_test_results_npy)\n",
    "\n",
    "np.save(file=('%s/%s/%s' % (results_folder, results_subfolder, 'fx_labels')), arr=fx_labels_npy)"
   ],
   "id": "f2bafb173d80226d",
   "outputs": [],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
